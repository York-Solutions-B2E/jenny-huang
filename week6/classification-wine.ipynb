{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For each of the below Classifiers, do the following:\n",
    "\n",
    "1. Evaluate its performance on the sample 'wine' dataset built into scikit-learn\n",
    "2. Learn and explain how the model works, and if it is binary / multi classification.\n",
    "3. Attempt to explain why the model performed how it did with the given dataset.\n",
    "\n",
    "* Logistic Regression\n",
    "* Decision Trees\n",
    "* Random Forest\n",
    "* Support Vector Machines (SVM) (Both with linear kernels and non-linear kernels!)\n",
    "* Naive Bayes\n",
    "* K-Nearest Neighbors (KNN)\n",
    "* Gradient Boosting Machines (GBM)\n",
    "* Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics.pairwise import distance_metrics\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "['class_0' 'class_1' 'class_2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_wine()\n",
    "\n",
    "X = data.data   #input parameters \n",
    "y = data.target #classification output\n",
    "df = pd.DataFrame(X, columns = data.feature_names)\n",
    "df[\"target\"] = y\n",
    "\n",
    "#outputs is 0, 1, 2, no other specification\n",
    "#13 input parameters \n",
    "print(df['target'].unique())\n",
    "print(data.target_names)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, SVC, SVC, GaussianNB, KNeighborsClassifier,GradientBoostingClassifier,LinearDiscriminantAnalysis]\n",
    "names = [\"logistic\", \"decision tree\", \"random forest\", \"SVM linear\", \"SVM nonlinear\", \"naive bayes\", \"k neighbors\", \"gradient boosting\", \"LDA\"]\n",
    "model_stats = pd.DataFrame(columns = ['model', 'accuracy', 'precision', 'recall', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic\n",
      "decision tree\n",
      "Making <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "random forest\n",
      "Making <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "SVM linear\n",
      "SVM nonlinear\n",
      "naive bayes\n",
      "Making <class 'sklearn.naive_bayes.GaussianNB'>\n",
      "k neighbors\n",
      "Making <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "gradient boosting\n",
      "Making <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA\n",
      "Making <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(classifiers)):\n",
    "    print(names[i])\n",
    "    match names[i]:\n",
    "        case \"logistic\":\n",
    "            model = classifiers[i](max_iter = 5000)\n",
    "        \n",
    "        case \"SVM linear\":\n",
    "            model = classifiers[i](kernel = 'linear')\n",
    "        \n",
    "        case \"SVM nonlinear\":\n",
    "            model = classifiers[i](kernel = 'rbf')\n",
    "        \n",
    "        case _: \n",
    "            print(f\"Making {classifiers[i]}\")\n",
    "            model = classifiers[i]()\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    a = accuracy_score(y_test, pred) #% of correct predictions (True Pos + True Neg)/Total   \n",
    "    p = precision_score(y_test, pred, average = 'weighted') #how many true positives \n",
    "    r= recall_score(y_test, pred, average = 'weighted')\n",
    "    model_stats.loc[len(model_stats.index)] = [names[i], a, p, r, a + p + r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  model with best overall performace is \n",
      "           model  accuracy  precision    recall       sum\n",
      "2  random forest  0.977778   0.979012  0.977778  2.934568\n",
      "8            LDA  1.000000   1.000000  1.000000  3.000000\n",
      "The  model with best precision is \n",
      "model        random forest\n",
      "accuracy          0.977778\n",
      "precision         0.979012\n",
      "recall            0.977778\n",
      "sum               2.934568\n",
      "Name: 2, dtype: object\n",
      "The  model with best accuracy is \n",
      "model        random forest\n",
      "accuracy          0.977778\n",
      "precision         0.979012\n",
      "recall            0.977778\n",
      "sum               2.934568\n",
      "Name: 2, dtype: object\n",
      "The  model with best recall is \n",
      "model        random forest\n",
      "accuracy          0.977778\n",
      "precision         0.979012\n",
      "recall            0.977778\n",
      "sum               2.934568\n",
      "Name: 2, dtype: object\n",
      "model        SVM nonlinear\n",
      "accuracy          0.577778\n",
      "precision         0.411207\n",
      "recall            0.577778\n",
      "sum               1.566762\n",
      "Name: 4, dtype: object\n",
      "model        k neighbors\n",
      "accuracy        0.688889\n",
      "precision       0.691979\n",
      "recall          0.688889\n",
      "sum             2.069757\n",
      "Name: 6, dtype: object\n",
      "model        decision tree\n",
      "accuracy          0.888889\n",
      "precision         0.890873\n",
      "recall            0.888889\n",
      "sum               2.668651\n",
      "Name: 1, dtype: object\n",
      "model        logistic\n",
      "accuracy     0.933333\n",
      "precision     0.93287\n",
      "recall       0.933333\n",
      "sum          2.799537\n",
      "Name: 0, dtype: object\n",
      "model        SVM linear\n",
      "accuracy       0.955556\n",
      "precision      0.958179\n",
      "recall         0.955556\n",
      "sum             2.86929\n",
      "Name: 3, dtype: object\n",
      "model        random forest\n",
      "accuracy          0.977778\n",
      "precision         0.979012\n",
      "recall            0.977778\n",
      "sum               2.934568\n",
      "Name: 2, dtype: object\n",
      "model        gradient boosting\n",
      "accuracy              0.977778\n",
      "precision             0.979365\n",
      "recall                0.977778\n",
      "sum                   2.934921\n",
      "Name: 7, dtype: object\n",
      "model        naive bayes\n",
      "accuracy             1.0\n",
      "precision            1.0\n",
      "recall               1.0\n",
      "sum                  3.0\n",
      "Name: 5, dtype: object\n",
      "model        LDA\n",
      "accuracy     1.0\n",
      "precision    1.0\n",
      "recall       1.0\n",
      "sum          3.0\n",
      "Name: 8, dtype: object\n"
     ]
    }
   ],
   "source": [
    "model_stats = model_stats.sort_values('sum')\n",
    "max_sum = model_stats[\"sum\"].max()\n",
    "sum_max = model_stats.index[model_stats['sum'] == max_sum].tolist()\n",
    "pre_max = model_stats[\"precision\"].idxmax()\n",
    "acc_max = model_stats[\"accuracy\"].idxmax()\n",
    "re_max = model_stats[\"recall\"].idxmax()\n",
    "best = model_stats.iloc[sum_max]\n",
    "best_p = model_stats.iloc[pre_max]\n",
    "best_a = model_stats.iloc[acc_max]\n",
    "best_r = model_stats.iloc[re_max]\n",
    "print(f\"The  model with best overall performace is \\n{best}\")\n",
    "print(f\"The  model with best precision is \\n{best_p}\")\n",
    "print(f\"The  model with best accuracy is \\n{best_a}\")\n",
    "print(f\"The  model with best recall is \\n{best_r}\")\n",
    "\n",
    "for i in range(len(model_stats.index)):\n",
    "    print(model_stats.iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistic Regression\n",
    "1. Evaluate its performance on the sample 'wine' dataset built into scikit-learn\n",
    "Name: 1, dtype: object\n",
    "model        logistic\n",
    "accuracy     0.933333\n",
    "precision     0.93287\n",
    "recall       0.933333\n",
    "2. Learn and explain how the model works, and if it is binary / multi classification.\n",
    "    * Fits the data along a logistic curve\n",
    "    * For multinomial data, uses multiple regressions\n",
    "3. Attempt to explain why the model performed how it did with the given dataset.\n",
    "\n",
    "* Decision Tree\n",
    "1. Evaluate its performance on the sample 'wine' dataset built into scikit-learn\n",
    "2. Learn and explain how the model works, and if it is binary / multi classification.\n",
    "    * Uses trees to classify data, where each node is a state and each branch is a condition\n",
    "3. Attempt to explain why the model performed how it did with the given dataset.\n",
    "\n",
    "* Random Forest\n",
    "1. Evaluate its performance on the sample 'wine' dataset built into scikit-learn\n",
    "2. Learn and explain how the model works, and if it is binary / multi classification.\n",
    "    * \n",
    "3. Attempt to explain why the model performed how it did with the given dataset.\n",
    "\n",
    "* Support Vector Machines (SVM) (Both with linear kernels and non-linear kernels!)\n",
    "1. Evaluate its performance on the sample 'wine' dataset built into scikit-learn\n",
    "2. Learn and explain how the model works, and if it is binary / multi classification.\n",
    "    * \n",
    "3. Attempt to explain why the model performed how it did with the given dataset.\n",
    "\n",
    "* Naive Bayes\n",
    "1. Evaluate its performance on the sample 'wine' dataset built into scikit-learn\n",
    "2. Learn and explain how the model works, and if it is binary / multi classification.\n",
    "    * Assumes all input features are independent and of equal importance\n",
    "3. Attempt to explain why the model performed how it did with the given dataset.\n",
    "\n",
    "* K-Nearest Neighbors (KNN)\n",
    "1. Evaluate its performance on the sample 'wine' dataset built into scikit-learn\n",
    "2. Learn and explain how the model works, and if it is binary / multi classification.\n",
    "    * \n",
    "3. Attempt to explain why the model performed how it did with the given dataset.\n",
    "\n",
    "* Gradient Boosting Machines (GBM)\n",
    "1. Evaluate its performance on the sample 'wine' dataset built into scikit-learn\n",
    "2. Learn and explain how the model works, and if it is binary / multi classification.\n",
    "    * \n",
    "3. Attempt to explain why the model performed how it did with the given dataset.\n",
    "\n",
    "* Linear Discriminant Analysis (LDA)\n",
    "1. Evaluate its performance on the sample 'wine' dataset built into scikit-learn\n",
    "2. Learn and explain how the model works, and if it is binary / multi classification.\n",
    "    * \n",
    "3. Attempt to explain why the model performed how it did with the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 0 2 2 0 2 2 2 0 2 0 0 1 0 2 1 1 2 0 2 0 1 2 2 1 1 2 1 2 1 2 0 1 1 1\n",
      " 2 1 0 0 0 0 1 0]\n",
      "[2 2 0 0 2 2 0 2 2 2 0 2 0 0 1 0 2 1 1 2 0 2 0 1 2 2 1 1 2 1 2 1 2 0 1 1 1\n",
      " 2 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "test = LinearDiscriminantAnalysis()\n",
    "test.fit(X_train, y_train)\n",
    "pred = test.predict(X_test)\n",
    "a = accuracy_score(y_test, pred) #% of correct predictions (True Pos + True Neg)/Total   \n",
    "p = precision_score(y_test, pred, average = 'weighted') #how many true positives \n",
    "r= recall_score(y_test, pred, average = 'weighted')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
