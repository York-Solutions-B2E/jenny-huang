{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import VALID_METRICS\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics.pairwise import distance_metrics\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = data.data   #input parameters \n",
    "y = data.target #classification output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore data using pandas\n",
    "df = pd.DataFrame(X, columns = data.feature_names)\n",
    "df[\"target\"] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into testing vs training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 16)\n",
    "#test size : what proportion of data for training , random_state : options for randomization seed, if you don't pass this then each time u run the split u will receive a new training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning algorithm\n",
    "knn_model = KNeighborsClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Algorithm: K Nearest Neighbors\n",
    "* A classification algorithm \n",
    "* Assign a label to n based on the most common value of its k nearest neighbors\n",
    "* Analogous to regression but is used for discrete values \n",
    "\n",
    "#### SKLearning KNeighborsClassifier()\n",
    "* n_neighbors : default = 5\n",
    "* weights : 'uniform' OR 'distance'\n",
    "    - how points are weighted, either uniformly or based on distance\n",
    "    - distance weights are useful when u have multiple clusters\n",
    "* algorithm : 'auto', 'ball_tree', 'kd_tree', 'brute' : default = 'auto' \n",
    "    * search algorithm to find the nearest neighbors\n",
    "    * 'auto' will automatically select based on data\n",
    "    * mostly a performance (i.e. runtime) parameter\n",
    "* leaf_size : int : default = 30\n",
    "    * size of leaf passed to search algorithm (KD or Ball Trees)\n",
    "* p : float : default = 2\n",
    "    * power parameter for Minkowski metric (x^p + y^p)\n",
    "    * n = 1 is manhattan distance\n",
    "    * n = 2 is euclidian\n",
    "* metric : default = 'minkowski'\n",
    "    * distance metric\n",
    "    * see https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html#sklearn.metrics.pairwise.distance_metrics for all metrics\n",
    "* metric_params : \n",
    "    * addl args for metric, see above\n",
    "* n_jobs : int : default = None\n",
    "    * number of parallel searches \n",
    "    * prolly just affects processing time ? \n",
    "\n",
    "### Sources\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "* https://www.ibm.com/topics/knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model using training\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "#predict using the test data\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "#check prediction performance \n",
    "accuracy = accuracy_score(y_test, knn_pred) #% of correct predictions (True Pos + True Neg)/Total\n",
    "\n",
    "precision = precision_score(y_test, knn_pred) #how many true positives \n",
    "\n",
    "recall = recall_score(y_test, knn_pred)\n",
    "\n",
    "confusion = confusion_matrix(y_test, knn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "* A good model will maximize all of these metrics \n",
    "### Accuracy\n",
    "* How many correct predictions (pos and neg) out of total predictions \n",
    "### Precision\n",
    "* How many true positives / total pos (T and F)\n",
    "* How many misdiagnosed cases\n",
    "### Recall\n",
    "* TP / (TP + FN)\n",
    "* How many cases did you miss!\n",
    "\n",
    "### Confusion Matrix\n",
    "* Returns 2x2 with total values of: <br>\n",
    "TP | FP <br>\n",
    "FN | TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  model with best overall performace is \n",
      "    Neighbors Search Alg   Weights  Accuracy  Precision    Recall       Sum\n",
      "0           1  ball_tree   uniform   0.93007   0.909091  0.989011  2.828172\n",
      "1           1  ball_tree  distance   0.93007   0.909091  0.989011  2.828172\n",
      "2           1    kd_tree   uniform   0.93007   0.909091  0.989011  2.828172\n",
      "3           1    kd_tree  distance   0.93007   0.909091  0.989011  2.828172\n",
      "4           1      brute   uniform   0.93007   0.909091  0.989011  2.828172\n",
      "5           1      brute  distance   0.93007   0.909091  0.989011  2.828172\n",
      "7           2  ball_tree  distance   0.93007   0.909091  0.989011  2.828172\n",
      "9           2    kd_tree  distance   0.93007   0.909091  0.989011  2.828172\n",
      "11          2      brute  distance   0.93007   0.909091  0.989011  2.828172\n",
      "The  model with best precision is \n",
      "Neighbors            14\n",
      "Search Alg    ball_tree\n",
      "Weights         uniform\n",
      "Accuracy        0.93007\n",
      "Precision      0.926316\n",
      "Recall         0.967033\n",
      "Sum            2.823419\n",
      "Name: 78, dtype: object\n",
      "The  model with best accuracy is \n",
      "Neighbors             1\n",
      "Search Alg    ball_tree\n",
      "Weights         uniform\n",
      "Accuracy        0.93007\n",
      "Precision      0.909091\n",
      "Recall         0.989011\n",
      "Sum            2.828172\n",
      "Name: 0, dtype: object\n",
      "The  model with best recall is \n",
      "Neighbors             1\n",
      "Search Alg    ball_tree\n",
      "Weights         uniform\n",
      "Accuracy        0.93007\n",
      "Precision      0.909091\n",
      "Recall         0.989011\n",
      "Sum            2.828172\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Finding best model based on parameters \n",
    "stats = pd.DataFrame(columns = [\"Neighbors\", \"Search Alg\", \"Weights\", \"Accuracy\", \"Precision\", \"Recall\", \"Sum\"])\n",
    "algorithms = ['ball_tree', 'kd_tree', 'brute']\n",
    "weights = ['uniform', 'distance']\n",
    "for x in range(1, 50):\n",
    "    for alg in algorithms: \n",
    "        # dist_metrics = VALID_METRICS[alg]\n",
    "        # print(dist_metrics)\n",
    "        for w in weights: \n",
    "            knn_model = KNeighborsClassifier(n_neighbors = x, algorithm=alg, weights=w)\n",
    "            knn_model.fit(X_train, y_train)\n",
    "            knn_pred = knn_model.predict(X_test)\n",
    "            a = accuracy_score(y_test, knn_pred) #% of correct predictions (True Pos + True Neg)/Total   \n",
    "            p = precision_score(y_test, knn_pred) #how many true positives \n",
    "            r= recall_score(y_test, knn_pred)\n",
    "            stats.loc[len(stats.index)] = [x, alg, w, a, p, r, a + p + r]\n",
    "max_sum = stats[\"Sum\"].max()\n",
    "sum_max = stats.index[stats['Sum'] == max_sum].tolist()\n",
    "pre_max = stats[\"Precision\"].idxmax()\n",
    "acc_max = stats[\"Accuracy\"].idxmax()\n",
    "re_max = stats[\"Recall\"].idxmax()\n",
    "best = stats.iloc[sum_max]\n",
    "best_p = stats.iloc[pre_max]\n",
    "best_a = stats.iloc[acc_max]\n",
    "best_r = stats.iloc[re_max]\n",
    "print(f\"The  model with best overall performace is \\n{best}\")\n",
    "print(f\"The  model with best precision is \\n{best_p}\")\n",
    "print(f\"The  model with best accuracy is \\n{best_a}\")\n",
    "print(f\"The  model with best recall is \\n{best_r}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "* fit a linear curve to divide the data space into 2 sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model using training\n",
    "lr_model = LogisticRegression(max_iter = 3000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "#predict using the test data\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "#check prediction performance \n",
    "accuracy = accuracy_score(y_test, lr_pred) #% of correct predictions (True Pos + True Neg)/Total\n",
    "\n",
    "precision = precision_score(y_test, lr_pred) #how many true positives \n",
    "\n",
    "recall = recall_score(y_test, lr_pred)\n",
    "\n",
    "confusion = confusion_matrix(y_test, lr_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)\n",
    "* Basically high dimensionality linear regression ; fit a hyperplane to divide the data into 2 segments \n",
    "* can perform non-linear transformation to get data into correct shape (kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel = 'linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "#check prediction performance \n",
    "accuracy = accuracy_score(y_test, svm_pred) #% of correct predictions (True Pos + True Neg)/Total\n",
    "\n",
    "precision = precision_score(y_test, svm_pred) #how many true positives \n",
    "\n",
    "recall = recall_score(y_test, svm_pred)\n",
    "\n",
    "confusion = confusion_matrix(y_test, svm_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
