{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Comprehension\n",
    "* Get all integers out of a list of numbers, e.x. [1,2.5,100.3,3.0,-1.5,-5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, -5]\n"
     ]
    }
   ],
   "source": [
    "def int_list(lst):\n",
    "    return [int(x) for x in lst if x == int(x)]\n",
    "\n",
    "test = int_list([1,2.5,100.3,3.0,-1.5,-5])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find all numbers from 1-1000 that have a 3 in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 13, 23, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 53, 63, 73, 83, 93, 103, 113, 123, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 143, 153, 163, 173, 183, 193, 203, 213, 223, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 243, 253, 263, 273, 283, 293, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 403, 413, 423, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 443, 453, 463, 473, 483, 493, 503, 513, 523, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 543, 553, 563, 573, 583, 593, 603, 613, 623, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 643, 653, 663, 673, 683, 693, 703, 713, 723, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 743, 753, 763, 773, 783, 793, 803, 813, 823, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 843, 853, 863, 873, 883, 893, 903, 913, 923, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 943, 953, 963, 973, 983, 993]\n"
     ]
    }
   ],
   "source": [
    "threes = [x for x in range(1,1001) if \"3\" in str(x)]\n",
    "print(threes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Count the number of alphabetic characters in a string (a-z, lower case or upper case)\n",
    "-- I didn't use list comprehension :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "def count_alpha(str):\n",
    "    return sum(1 for chr in str if chr in string.ascii_letters)\n",
    "\n",
    "print(count_alpha(\"heehee123\")== 6)\n",
    "print(count_alpha(\"\")== 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* [Challenge - requires nesting] - Find all numbers between 1-1000 that are not divisble by any number between 2 and 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 121, 127, 131, 137, 139, 143, 149, 151, 157, 163, 167, 169, 173, 179, 181, 187, 191, 193, 197, 199, 209, 211, 221, 223, 227, 229, 233, 239, 241, 247, 251, 253, 257, 263, 269, 271, 277, 281, 283, 289, 293, 299, 307, 311, 313, 317, 319, 323, 331, 337, 341, 347, 349, 353, 359, 361, 367, 373, 377, 379, 383, 389, 391, 397, 401, 403, 407, 409, 419, 421, 431, 433, 437, 439, 443, 449, 451, 457, 461, 463, 467, 473, 479, 481, 487, 491, 493, 499, 503, 509, 517, 521, 523, 527, 529, 533, 541, 547, 551, 557, 559, 563, 569, 571, 577, 583, 587, 589, 593, 599, 601, 607, 611, 613, 617, 619, 629, 631, 641, 643, 647, 649, 653, 659, 661, 667, 671, 673, 677, 683, 689, 691, 697, 701, 703, 709, 713, 719, 727, 731, 733, 737, 739, 743, 751, 757, 761, 767, 769, 773, 779, 781, 787, 793, 797, 799, 803, 809, 811, 817, 821, 823, 827, 829, 839, 841, 851, 853, 857, 859, 863, 869, 871, 877, 881, 883, 887, 893, 899, 901, 907, 911, 913, 919, 923, 929, 937, 941, 943, 947, 949, 953, 961, 967, 971, 977, 979, 983, 989, 991, 997]\n"
     ]
    }
   ],
   "source": [
    "lst = [x for x in range(1,1001) if all(x % i != 0 for i in range(2,10))] #YAAAAAAS this one was so effing annoying\n",
    "print(lst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL/Big Query (Using the noaa historic severe storms dataset).\n",
    "* Find out what state has had the most historic severe storms between 1980 and 1995 : TENNESSEE \n",
    "* This code is really long and inefficient but this was the only way I could figure it out lmao sorry D: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH s80 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1980` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "s81 as\n",
    "(SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1981` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "s82 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1982` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "\n",
    "s83 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1983` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "\n",
    "s84 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1984` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "\n",
    "s85 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1985` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "\n",
    "s86 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1986` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "\n",
    "s87 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1987` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "\n",
    "s88 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1988` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "\n",
    "s89 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1989` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "\n",
    "s90 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1990` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "\n",
    "s91 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1991` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "s92 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1992` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "\n",
    "s93 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1993` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "\n",
    "s94 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1994` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000),\n",
    "\n",
    "s95 as\n",
    "  (SELECT state, COUNT(event_id) as num_events\n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_1995` \n",
    "  GROUP BY state \n",
    "  ORDER BY num_events DESC\n",
    "  LIMIT 1000)\n",
    "\n",
    "SELECT s80.state, \n",
    "s80.num_events + s81.num_events +  s82.num_events +  s83.num_events +  s84.num_events +  s85.num_events +  s86.num_events +  s87.num_events + s88.num_events +  s89.num_events +  s90.num_events + s91.num_events + s92.num_events + s93.num_events + s94.num_events + s95.num_events as total_events \n",
    "FROM s80 FULL JOIN s81 ON s80.state = s81.state\n",
    "FULL JOIN s82 ON s82.state = s81.state\n",
    "FULL JOIN s83 ON s83.state = s81.state\n",
    "FULL JOIN s84 ON s84.state = s81.state\n",
    "FULL JOIN s85 ON s85.state = s81.state\n",
    "FULL JOIN s86 ON s86.state = s81.state\n",
    "FULL JOIN s87 ON s87.state = s81.state\n",
    "FULL JOIN s88 ON s88.state = s81.state\n",
    "FULL JOIN s89 ON s89.state = s81.state\n",
    "FULL JOIN s90 ON s90.state = s81.state\n",
    "FULL JOIN s91 ON s91.state = s81.state \n",
    "FULL JOIN s92 ON s92.state = s81.state\n",
    "FULL JOIN s93 ON s93.state = s81.state\n",
    "FULL JOIN s94 ON s94.state = s81.state\n",
    "FULL JOIN s95 ON s95.state = s81.state\n",
    "\n",
    "ORDER BY total_events DESC\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the average crop damage for storms in 2011: 40133.495685522408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT AVG(damage_crops) as avg_crop_damage\n",
    "FROM `bigquery-public-data.noaa_historic_severe_storms.storms_2011` \n",
    "LIMIT 1000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What was the total number of direct and indirect deaths for storms in 2000? 521\n",
    "* What about the total number of direct or indirect injuries? 3658\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT SUM(deaths_indirect) + SUM(deaths_direct) as total_deaths, SUM(injuries_direct) + SUM(injuries_indirect) as total_injuries\n",
    "FROM `bigquery-public-data.noaa_historic_severe_storms.storms_2000` \n",
    "LIMIT 1000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Query / Python\n",
    "* Using the same dataset as above, download a CSV to parse in python of the 1000 worst storms in 2022 by magnitude when the magnitude type is \"MG\" or \"EG\" and the magnitude was at least 80\n",
    "* What percent of event types were thunderstorms vs high winds?\n",
    "* What state had the least number of these types of storms?  What state had the most?\n",
    "* What was the mean, median, and standard deviation of the magnitude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###MY SQL CODE TO GET THE NECESSARY DATA\n",
    "SELECT state, magnitude, event_type \n",
    "  FROM `bigquery-public-data.noaa_historic_severe_storms.storms_2022` \n",
    "  WHERE magnitude_type = \"MG\" OR magnitude_type = \"EG\" AND magnitude > 80\n",
    "  ORDER BY magnitude DESC\n",
    "  LIMIT 1000; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.4% of events were thunderstorms. 55.300000000000004% of events were high wind\n",
      "Max number of storms was 134 in Ca\n",
      "Min number of storms was 1 in Ha\n",
      "The average mag is 73.33 \n",
      "The median is 70.0 \n",
      "the std. dev is 9.830111901702848\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "class StormData:\n",
    "    def __init__(self, state, mag, event_type):\n",
    "        self.state = state\n",
    "        self.mag = mag\n",
    "        self.event_type = event_type\n",
    "    \n",
    "    def __str__(self):\n",
    "        return (f\"Storm event {self.event_type}, magnitude {self.mag} in {self.state}\")\n",
    "\n",
    "storm_data = []\n",
    "with open('storms.csv', 'r') as data_file:        #open file\n",
    "    reader = csv.reader(data_file)  #reads the file line by line\n",
    "    line_count = 0 #use to skip header row\n",
    "    for row in reader:\n",
    "        if line_count != 0:\n",
    "            new_data = StormData(row[0], float(row[1]), row[2])\n",
    "            storm_data.append(new_data)\n",
    "        line_count  += 1\n",
    "\n",
    "def percent_events(data_lst):\n",
    "    thunderstorms = [d for d in data_lst if d.event_type == \"thunderstorm wind\"]\n",
    "    high_winds = [d for d in data_lst if d.event_type == \"high wind\"]\n",
    "    percent_ts = len(thunderstorms)/len(data_lst)*100\n",
    "    percent_hw = len(high_winds)/len(data_lst)*100\n",
    "    return(f\"{percent_ts}% of events were thunderstorms. {percent_hw}% of events were high wind\")\n",
    "\n",
    "print(percent_events(storm_data))\n",
    "\n",
    "by_state = {}\n",
    "for d in storm_data:\n",
    "    if d.state not in by_state:\n",
    "        by_state[d.state] = 1\n",
    "    else: by_state[d.state] += 1\n",
    "\n",
    "max_storms = max(by_state.values()) # max age \n",
    "max_state = max(by_state, key = by_state.get)\n",
    "\n",
    "print(f\"Max number of storms was {max_storms} in {max_state}\")\n",
    "\n",
    "min_storms = min(by_state.values()) # max age \n",
    "min_state = min(by_state, key = by_state.get)\n",
    "print(f\"Min number of storms was {min_storms} in {min_state}\")\n",
    "\n",
    "mags = [d.mag for d in storm_data]\n",
    "avg_mag = np.mean(mags)\n",
    "median_mag = np.median(mags)\n",
    "std_mag = np.std(mags)\n",
    "\n",
    "print(f\"The average mag is {avg_mag} \\nThe median is {median_mag} \\nthe std. dev is {std_mag}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
