{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL\n",
    "* Extract, transform, load\n",
    "* Get data from multiple sources (DB, files, API, images)\n",
    "* Transform into usable format\n",
    "* Load data into storable form (DB, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from requests import get, HTTPError, ConnectionError\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>permalink</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>post_score</th>\n",
       "      <th>number_comments</th>\n",
       "      <th>flair</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[D] Simple Questions Thread</td>\n",
       "      <td>/r/MachineLearning/comments/18kkdbb/d_simple_q...</td>\n",
       "      <td>Please post your questions here instead of cre...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>2023-12-17 10:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[P] the Decimator, or how to plot a lot of points</td>\n",
       "      <td>/r/MachineLearning/comments/18nq5p6/p_the_deci...</td>\n",
       "      <td>The decimator is a function that removes point...</td>\n",
       "      <td>quicklyalienated76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>Project</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>2023-12-21 09:54:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[D] Deep dive into the MMLU (\"Are you smarter ...</td>\n",
       "      <td>/r/MachineLearning/comments/18ntia7/d_deep_div...</td>\n",
       "      <td>After all the hubbub around the MMLU (for exam...</td>\n",
       "      <td>brokensegue</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>2023-12-21 12:21:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[P] I built an open SotA image tagging model t...</td>\n",
       "      <td>/r/MachineLearning/comments/18nb15l/p_i_built_...</td>\n",
       "      <td>I'm a hobbyist ML researcher and finally, afte...</td>\n",
       "      <td>fpgaminer</td>\n",
       "      <td>0.95</td>\n",
       "      <td>154</td>\n",
       "      <td>48</td>\n",
       "      <td>Project</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>2023-12-20 19:34:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meta AI Residency Interview Question [D]</td>\n",
       "      <td>/r/MachineLearning/comments/18nio9k/meta_ai_re...</td>\n",
       "      <td>Was curious about this coding question that I ...</td>\n",
       "      <td>Immediate-Tailor-275</td>\n",
       "      <td>0.83</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>2023-12-21 02:58:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                        [D] Simple Questions Thread   \n",
       "1  [P] the Decimator, or how to plot a lot of points   \n",
       "2  [D] Deep dive into the MMLU (\"Are you smarter ...   \n",
       "3  [P] I built an open SotA image tagging model t...   \n",
       "4           Meta AI Residency Interview Question [D]   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  /r/MachineLearning/comments/18kkdbb/d_simple_q...   \n",
       "1  /r/MachineLearning/comments/18nq5p6/p_the_deci...   \n",
       "2  /r/MachineLearning/comments/18ntia7/d_deep_div...   \n",
       "3  /r/MachineLearning/comments/18nb15l/p_i_built_...   \n",
       "4  /r/MachineLearning/comments/18nio9k/meta_ai_re...   \n",
       "\n",
       "                                                text                author  \\\n",
       "0  Please post your questions here instead of cre...         AutoModerator   \n",
       "1  The decimator is a function that removes point...    quicklyalienated76   \n",
       "2  After all the hubbub around the MMLU (for exam...           brokensegue   \n",
       "3  I'm a hobbyist ML researcher and finally, afte...             fpgaminer   \n",
       "4  Was curious about this coding question that I ...  Immediate-Tailor-275   \n",
       "\n",
       "   upvote_ratio  post_score  number_comments       flair whitelist_status  \\\n",
       "0          0.75           4               22  Discussion          all_ads   \n",
       "1          0.85          14                1     Project          all_ads   \n",
       "2          1.00           7                4  Discussion          all_ads   \n",
       "3          0.95         154               48     Project          all_ads   \n",
       "4          0.83          27               23  Discussion          all_ads   \n",
       "\n",
       "                 date  \n",
       "0 2023-12-17 10:00:19  \n",
       "1 2023-12-21 09:54:54  \n",
       "2 2023-12-21 12:21:28  \n",
       "3 2023-12-20 19:34:39  \n",
       "4 2023-12-21 02:58:28  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_endpoint = 'https://www.reddit.com/r/machinelearning/.json'\n",
    "json_data = None\n",
    "try: \n",
    "    req = get(reddit_endpoint, headers = {\"User-agent\": \"max-etl-pipeline\"})\n",
    "    json_data = req.json()\n",
    "except (HTTPError, ConnectionError) as err:\n",
    "    print(err)\n",
    "\n",
    "with open(\"data.json\", \"w\") as outfile:\n",
    "    json_str = json.dump(json_data, outfile, indent = 4)\n",
    "\n",
    "with open(\"data.json\", 'r') as jf: \n",
    "    data = json.load(jf)\n",
    "\n",
    "post_data = data[\"data\"][\"children\"]\n",
    "df_rows = []\n",
    "\n",
    "for post in post_data:\n",
    "    pdata =  post['data']\n",
    "    post_title =pdata[\"title\"]\n",
    "    post_text = pdata[\"selftext\"]\n",
    "    post_author = pdata[\"author\"]\n",
    "    post_upvote_ratio = pdata[\"upvote_ratio\"]\n",
    "    post_score = pdata[\"score\"]\n",
    "    post_flair = pdata[\"link_flair_text\"]\n",
    "    post_whitelist = pdata[\"parent_whitelist_status\"]\n",
    "    post_num_comments = pdata[\"num_comments\"]\n",
    "    post_permalink = pdata[\"permalink\"]\n",
    "    post_date = datetime.datetime.fromtimestamp(pdata[\"created_utc\"])      #FIX\n",
    "\n",
    "    #add each data item to appropriate list\n",
    "    datalst = [post_title, post_permalink, post_text, post_author, post_upvote_ratio, post_score, post_num_comments, post_flair, post_whitelist,post_date]\n",
    "    df_rows.append(datalst)\n",
    "\n",
    "colnames = [\"title\", \"permalink\" , \"text\", \"author\", \"upvote_ratio\", \"post_score\", \"number_comments\", \"flair\", \"whitelist_status\", \"date\"]\n",
    "\n",
    "df = pd.DataFrame(df_rows, columns = colnames)\n",
    "\n",
    "\n",
    "df.to_csv('ml_reddit_data.csv')\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#title, author fullname, clicked\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kind': 'Listing', 'data': {'after': 't3_18na690', 'dist': 27, 'modhash': '', 'geo_filter': None, 'children': [{'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\\n\\nThread will stay alive until next one so keep posting after the date in the title.\\n\\nThanks to everyone for answering questions in the previous thread!', 'author_fullname': 't2_6l4z3', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] Simple Questions Thread', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18kkdbb', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.63, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': True, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1702828819.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!&lt;/p&gt;\\n\\n&lt;p&gt;Thread will stay alive until next one so keep posting after the date in the title.&lt;/p&gt;\\n\\n&lt;p&gt;Thanks to everyone for answering questions in the previous thread!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': 'new', 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18kkdbb', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'AutoModerator', 'discussion_type': None, 'num_comments': 21, 'send_replies': False, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/', 'parent_whitelist_status': 'all_ads', 'stickied': True, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/', 'subreddit_subscribers': 2842618, 'created_utc': 1702828819.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'What really caught your eye so far this year? Both high profile applications but also research innovations which may shape the field for decades to come.', 'author_fullname': 't2_3yrr2', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': \"[D] What are 2023's top innovations in ML/AI outside of LLM stuff?\", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18hnh8p', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.99, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 365, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 365, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1702491999.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What really caught your eye so far this year? Both high profile applications but also research innovations which may shape the field for decades to come.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18hnh8p', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'prescod', 'discussion_type': None, 'num_comments': 136, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18hnh8p/d_what_are_2023s_top_innovations_in_mlai_outside/', 'parent_whitelist_status': 'all_ads', 'stickied': True, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18hnh8p/d_what_are_2023s_top_innovations_in_mlai_outside/', 'subreddit_subscribers': 2842618, 'created_utc': 1702491999.0, 'num_crossposts': 1, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'The decimator is a function that removes points in the plot while keeping all the \"value/information\" of a chart. The post features examples with times series and clustering.\\n\\n[https://www.taipy.io/posts/big-data-charting-strategies-in-python](https://www.taipy.io/posts/big-data-charting-strategies-in-python)', 'author_fullname': 't2_tfe7ylgn', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[P] the Decimator, or how to plot a lot of points', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_18nq5p6', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.83, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 11, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 11, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703174094.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The decimator is a function that removes points in the plot while keeping all the &amp;quot;value/information&amp;quot; of a chart. The post features examples with times series and clustering.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\"https://www.taipy.io/posts/big-data-charting-strategies-in-python\"&gt;https://www.taipy.io/posts/big-data-charting-strategies-in-python&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nq5p6', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'quicklyalienated76', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nq5p6/p_the_decimator_or_how_to_plot_a_lot_of_points/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nq5p6/p_the_decimator_or_how_to_plot_a_lot_of_points/', 'subreddit_subscribers': 2842618, 'created_utc': 1703174094.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'I\\'m a hobbyist ML researcher and finally, after a year of work, built a state of the art machine vision model from scratch. It\\'s ViT-B/16 based, 448x448x3 input, 91M parameters, trained for 660M samples, with multi-label classification as the target task, on over 5000 unique tags.\\n\\nAll the big foundation vision models today were trained on heavily filtered datasets, greatly limiting the concepts they can represent, in line with arbitrary sets of rules for what is deemed \"wholesome\" by leading tech companies.  Everything from innocuous to spicy is on the chopping block of those filters.  And because CLIP pervades the industry, from StableDiffusion to LLaVA, so does OpenAI\\'s sensibilities.\\n\\nMy goal was to build a vision model for tagging images, mainly for labelling images for SD finetunes, but which wasn\\'t as heavily filtered and handicapped as CLIP/BLIP/LLaVA.  Something more inclusive, diverse, and sex positive.\\n\\nStarting from the wonderful work of SmilingWolf (https://github.com/SmilingWolf/SW-CV-ModelZoo) and the Danbooru2021 dataset, I iterated for a year on the model, training, and manually labeling a thousand images to help the model generalize beyond the danbooru domain.\\n\\nI\\'m releasing the first version of this model, dubbed JoyTag, today: https://github.com/fpgaminer/joytag\\n\\nIt achieves a mean F1 score of 0.578 across all of its over 5000 tags and across both the anime/manga styled images of the original danbooru dataset, but also photographs and other mediums thanks to the auxiliary training data I provided to it.\\n\\nIt was quite the struggle getting to this point, and I probably spent more time and money than any sane person should have.  I learned a lot about dealing with datasets as large as danbooru2021, training models at scale, and how to keep yourself awake all night so your 8xA100 rental doesn\\'t crash and blow all your money.\\n\\nIn my manual testing outside of even the validation set, the model has generalized well to unseen images, so I\\'m quite happy with the results thus far.  There\\'s plenty more work to do expanding its dataset to improve that F1 score further, and roundout its weak points.  With inclusivity and diversity being a major goal of this project, I\\'m disappointed by some of its remaining limitations (as documented in the GitHub README).  But I\\'m already busy manually tagging more images using my model-augmented workflow.\\n\\nI\\'m happy to answer questions about the project, the training procedure, anything.  All the training parameters are documented on GitHub, but there are so many little details that were hard won over the year.  Like that damned loss multiplier.  Ugh.\\n\\nGithub: https://github.com/fpgaminer/joytag\\nModel download: https://huggingface.co/fancyfeast/joytag/tree/main\\nDemo: https://huggingface.co/spaces/fancyfeast/joytag', 'author_fullname': 't2_bkfa9', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': \"[P] I built an open SotA image tagging model to do what CLIP won't\", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18nb15l', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.95, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 138, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 138, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703122479.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a hobbyist ML researcher and finally, after a year of work, built a state of the art machine vision model from scratch. It&amp;#39;s ViT-B/16 based, 448x448x3 input, 91M parameters, trained for 660M samples, with multi-label classification as the target task, on over 5000 unique tags.&lt;/p&gt;\\n\\n&lt;p&gt;All the big foundation vision models today were trained on heavily filtered datasets, greatly limiting the concepts they can represent, in line with arbitrary sets of rules for what is deemed &amp;quot;wholesome&amp;quot; by leading tech companies.  Everything from innocuous to spicy is on the chopping block of those filters.  And because CLIP pervades the industry, from StableDiffusion to LLaVA, so does OpenAI&amp;#39;s sensibilities.&lt;/p&gt;\\n\\n&lt;p&gt;My goal was to build a vision model for tagging images, mainly for labelling images for SD finetunes, but which wasn&amp;#39;t as heavily filtered and handicapped as CLIP/BLIP/LLaVA.  Something more inclusive, diverse, and sex positive.&lt;/p&gt;\\n\\n&lt;p&gt;Starting from the wonderful work of SmilingWolf (&lt;a href=\"https://github.com/SmilingWolf/SW-CV-ModelZoo\"&gt;https://github.com/SmilingWolf/SW-CV-ModelZoo&lt;/a&gt;) and the Danbooru2021 dataset, I iterated for a year on the model, training, and manually labeling a thousand images to help the model generalize beyond the danbooru domain.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m releasing the first version of this model, dubbed JoyTag, today: &lt;a href=\"https://github.com/fpgaminer/joytag\"&gt;https://github.com/fpgaminer/joytag&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;It achieves a mean F1 score of 0.578 across all of its over 5000 tags and across both the anime/manga styled images of the original danbooru dataset, but also photographs and other mediums thanks to the auxiliary training data I provided to it.&lt;/p&gt;\\n\\n&lt;p&gt;It was quite the struggle getting to this point, and I probably spent more time and money than any sane person should have.  I learned a lot about dealing with datasets as large as danbooru2021, training models at scale, and how to keep yourself awake all night so your 8xA100 rental doesn&amp;#39;t crash and blow all your money.&lt;/p&gt;\\n\\n&lt;p&gt;In my manual testing outside of even the validation set, the model has generalized well to unseen images, so I&amp;#39;m quite happy with the results thus far.  There&amp;#39;s plenty more work to do expanding its dataset to improve that F1 score further, and roundout its weak points.  With inclusivity and diversity being a major goal of this project, I&amp;#39;m disappointed by some of its remaining limitations (as documented in the GitHub README).  But I&amp;#39;m already busy manually tagging more images using my model-augmented workflow.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m happy to answer questions about the project, the training procedure, anything.  All the training parameters are documented on GitHub, but there are so many little details that were hard won over the year.  Like that damned loss multiplier.  Ugh.&lt;/p&gt;\\n\\n&lt;p&gt;Github: &lt;a href=\"https://github.com/fpgaminer/joytag\"&gt;https://github.com/fpgaminer/joytag&lt;/a&gt;\\nModel download: &lt;a href=\"https://huggingface.co/fancyfeast/joytag/tree/main\"&gt;https://huggingface.co/fancyfeast/joytag/tree/main&lt;/a&gt;\\nDemo: &lt;a href=\"https://huggingface.co/spaces/fancyfeast/joytag\"&gt;https://huggingface.co/spaces/fancyfeast/joytag&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/5gsQ9I_Rs5RkDMJ3_6apnKTs4T9mdy9pKeZJy7NOJ_A.jpg?auto=webp&amp;s=228cf2ca80fb2b37a4842d98bbcbfcec4aba4de1', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/5gsQ9I_Rs5RkDMJ3_6apnKTs4T9mdy9pKeZJy7NOJ_A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b62660ac17c4c93457894f8d122b4ed361c089b3', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/5gsQ9I_Rs5RkDMJ3_6apnKTs4T9mdy9pKeZJy7NOJ_A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=01a5be439ea7f93edee5419fdc68f3cb711d9a4e', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/5gsQ9I_Rs5RkDMJ3_6apnKTs4T9mdy9pKeZJy7NOJ_A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=89a74b5e1b18e047b6ebf98b16784f3adeffbdb9', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/5gsQ9I_Rs5RkDMJ3_6apnKTs4T9mdy9pKeZJy7NOJ_A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b119e6c1e113b88cb8db33c8e89b28fda16fe27e', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/5gsQ9I_Rs5RkDMJ3_6apnKTs4T9mdy9pKeZJy7NOJ_A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c5493b4820f63626dd839d3d3d0b12fbaf790698', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/5gsQ9I_Rs5RkDMJ3_6apnKTs4T9mdy9pKeZJy7NOJ_A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8c10300e7dfbdb03da3d782d246114c0cde9e467', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'Ztxf6vcQJWzgHPe62AqjAdUUPYqYLaIn-8aC_3U1H3M'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nb15l', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'fpgaminer', 'discussion_type': None, 'num_comments': 38, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nb15l/p_i_built_an_open_sota_image_tagging_model_to_do/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nb15l/p_i_built_an_open_sota_image_tagging_model_to_do/', 'subreddit_subscribers': 2842618, 'created_utc': 1703122479.0, 'num_crossposts': 2, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'I removed 50% of the weights from a top leaderboard LLM without negatively impacting the evals. \\n\\nUsing SparseML I was able to zero out 50% of the \\n\\nSOLAR-10.7B-Instruct-v1.0 weights. \\n\\nI then quantized the remaining weights to INT8. \\n\\nThe results are amazing! \\n\\n&amp;#x200B;\\n\\nhttps://preview.redd.it/uefy5u1hin7c1.png?width=927&amp;format=png&amp;auto=webp&amp;s=35f9c3a07ab3e7f3a0e22a7528adeafc71c4e8e5\\n\\nEven after pruning and quantizing the model to 50% I still got stellar zero-shot evaluation results. \\n\\n&amp;#x200B;\\n\\nTry the model:\\n\\n&amp;#x200B;\\n\\nhttps://preview.redd.it/r5tmixshin7c1.png?width=1999&amp;format=png&amp;auto=webp&amp;s=61370090bb0083fecde7b00310bda71527e2eb61\\n\\nInterestingly, the model is pruned and quantized in one shot. This means that no retraining is done. \\n\\nThe process works by using a calibration dataset to prune the model in blocks while adjusting the rest of the weights to ensure the model’s accuracy is not affected. \\n\\nThe algorithm used here is SparseGPT. \\n\\nSparseGPT is a post-training pruning method for compressing large language models such as GPT3 and Solar efficiently and accurately. The model can prune LLMs in one shot with minimal loss of accuracy. \\n\\nSince LLMs are usually overparameterized, you can remove most of the weights, improving latency and throughput during inference. \\n\\nCheck out the SOLAR-10.7B-Instruct-v1.0 model that has been pruned in one shot here: \\n\\nhttps://huggingface.co/neuralmagic/SOLAR-10.7B-Instruct-v1.0-pruned50-quant-ds\\n\\nLearn how to optimize your models in one shot: [https://github.com/neuralmagic/sparseml/tree/main/src/sparseml/transformers/sparsification/obcq](https://github.com/neuralmagic/sparseml/tree/main/src/sparseml/transformers/sparsification/obcq)\\n\\nLearn more about SparseGPT: https://neuralmagic.com/blog/sparsegpt-remove-100-billion-parameters-for-free/', 'author_fullname': 't2_a17lr8q', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] Removed 50% of the weights from a top leaderboard LLM without negatively impacting the evals', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': 86, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'uefy5u1hin7c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 66, 'x': 108, 'u': 'https://preview.redd.it/uefy5u1hin7c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=35db8958c7268bd9ceb849fb944398b570113a00'}, {'y': 133, 'x': 216, 'u': 'https://preview.redd.it/uefy5u1hin7c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4005519e12fe2db30172595d34c26bdd8babb32d'}, {'y': 197, 'x': 320, 'u': 'https://preview.redd.it/uefy5u1hin7c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4bcbc145bed781f44b077a5e2067cb3d28c4bdbe'}, {'y': 395, 'x': 640, 'u': 'https://preview.redd.it/uefy5u1hin7c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e9210bd2300146191cd67c0eb5cadf81407434ed'}], 's': {'y': 573, 'x': 927, 'u': 'https://preview.redd.it/uefy5u1hin7c1.png?width=927&amp;format=png&amp;auto=webp&amp;s=35f9c3a07ab3e7f3a0e22a7528adeafc71c4e8e5'}, 'id': 'uefy5u1hin7c1'}, 'r5tmixshin7c1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 99, 'x': 108, 'u': 'https://preview.redd.it/r5tmixshin7c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=13ccf227c49fd6efd9b4801ea7eff820aa9334c0'}, {'y': 199, 'x': 216, 'u': 'https://preview.redd.it/r5tmixshin7c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fccadd6cb3a048391d169be0a6c2b70f3495cc29'}, {'y': 295, 'x': 320, 'u': 'https://preview.redd.it/r5tmixshin7c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b34561455ec1a4283f84f54d0d3840fe30d13d4f'}, {'y': 590, 'x': 640, 'u': 'https://preview.redd.it/r5tmixshin7c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=633d25369aa582a6103648f8feecfce8d8e785a1'}, {'y': 885, 'x': 960, 'u': 'https://preview.redd.it/r5tmixshin7c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=372efb8bdcb6b602207a9ceb5591cca418e654af'}, {'y': 995, 'x': 1080, 'u': 'https://preview.redd.it/r5tmixshin7c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=00733356bbd238d3a187293158c6ab7f6eab6779'}], 's': {'y': 1843, 'x': 1999, 'u': 'https://preview.redd.it/r5tmixshin7c1.png?width=1999&amp;format=png&amp;auto=webp&amp;s=61370090bb0083fecde7b00310bda71527e2eb61'}, 'id': 'r5tmixshin7c1'}}, 'name': 't3_18nn7yg', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.62, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 19, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 19, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/EOnNUbef_DgazWlTsL-bnF4uZNbq5gF8LA-BUvv5Z8M.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703165853.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I removed 50% of the weights from a top leaderboard LLM without negatively impacting the evals. &lt;/p&gt;\\n\\n&lt;p&gt;Using SparseML I was able to zero out 50% of the &lt;/p&gt;\\n\\n&lt;p&gt;SOLAR-10.7B-Instruct-v1.0 weights. &lt;/p&gt;\\n\\n&lt;p&gt;I then quantized the remaining weights to INT8. &lt;/p&gt;\\n\\n&lt;p&gt;The results are amazing! &lt;/p&gt;\\n\\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/uefy5u1hin7c1.png?width=927&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=35f9c3a07ab3e7f3a0e22a7528adeafc71c4e8e5\"&gt;https://preview.redd.it/uefy5u1hin7c1.png?width=927&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=35f9c3a07ab3e7f3a0e22a7528adeafc71c4e8e5&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Even after pruning and quantizing the model to 50% I still got stellar zero-shot evaluation results. &lt;/p&gt;\\n\\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\\n\\n&lt;p&gt;Try the model:&lt;/p&gt;\\n\\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/r5tmixshin7c1.png?width=1999&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=61370090bb0083fecde7b00310bda71527e2eb61\"&gt;https://preview.redd.it/r5tmixshin7c1.png?width=1999&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=61370090bb0083fecde7b00310bda71527e2eb61&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Interestingly, the model is pruned and quantized in one shot. This means that no retraining is done. &lt;/p&gt;\\n\\n&lt;p&gt;The process works by using a calibration dataset to prune the model in blocks while adjusting the rest of the weights to ensure the model’s accuracy is not affected. &lt;/p&gt;\\n\\n&lt;p&gt;The algorithm used here is SparseGPT. &lt;/p&gt;\\n\\n&lt;p&gt;SparseGPT is a post-training pruning method for compressing large language models such as GPT3 and Solar efficiently and accurately. The model can prune LLMs in one shot with minimal loss of accuracy. &lt;/p&gt;\\n\\n&lt;p&gt;Since LLMs are usually overparameterized, you can remove most of the weights, improving latency and throughput during inference. &lt;/p&gt;\\n\\n&lt;p&gt;Check out the SOLAR-10.7B-Instruct-v1.0 model that has been pruned in one shot here: &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\"https://huggingface.co/neuralmagic/SOLAR-10.7B-Instruct-v1.0-pruned50-quant-ds\"&gt;https://huggingface.co/neuralmagic/SOLAR-10.7B-Instruct-v1.0-pruned50-quant-ds&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Learn how to optimize your models in one shot: &lt;a href=\"https://github.com/neuralmagic/sparseml/tree/main/src/sparseml/transformers/sparsification/obcq\"&gt;https://github.com/neuralmagic/sparseml/tree/main/src/sparseml/transformers/sparsification/obcq&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Learn more about SparseGPT: &lt;a href=\"https://neuralmagic.com/blog/sparsegpt-remove-100-billion-parameters-for-free/\"&gt;https://neuralmagic.com/blog/sparsegpt-remove-100-billion-parameters-for-free/&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/y5eBHk0xzO3Tqyffb3N02IR0W-D4g4u-dCDG-NO6yLk.jpg?auto=webp&amp;s=b0117b417bc4e1e6b57af9daab871ff633d66603', 'width': 1200, 'height': 648}, 'resolutions': [{'url': 'https://external-preview.redd.it/y5eBHk0xzO3Tqyffb3N02IR0W-D4g4u-dCDG-NO6yLk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2fff08f30f3ef3bf93aa23faf8d64fdbd7515b3d', 'width': 108, 'height': 58}, {'url': 'https://external-preview.redd.it/y5eBHk0xzO3Tqyffb3N02IR0W-D4g4u-dCDG-NO6yLk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cfd63c02fe0666690ec84e8294d9c9376df48e6f', 'width': 216, 'height': 116}, {'url': 'https://external-preview.redd.it/y5eBHk0xzO3Tqyffb3N02IR0W-D4g4u-dCDG-NO6yLk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f49f3ede4c08ce37a8ff8c3c8ab5545bcb5ea8a', 'width': 320, 'height': 172}, {'url': 'https://external-preview.redd.it/y5eBHk0xzO3Tqyffb3N02IR0W-D4g4u-dCDG-NO6yLk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c826dc0720fa2817ae9792d8295bcf9bd12e80fd', 'width': 640, 'height': 345}, {'url': 'https://external-preview.redd.it/y5eBHk0xzO3Tqyffb3N02IR0W-D4g4u-dCDG-NO6yLk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1a6e705ca668526b5fde2f4dac63d83232db7e9a', 'width': 960, 'height': 518}, {'url': 'https://external-preview.redd.it/y5eBHk0xzO3Tqyffb3N02IR0W-D4g4u-dCDG-NO6yLk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b744b867552b2c74a8eea6eea2318be6e4c4235d', 'width': 1080, 'height': 583}], 'variants': {}, 'id': 'mmKBFxIPYqY8HVR6aspDMWr04nggUDuRCtM24IQ_yDA'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nn7yg', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'mwitiderrick', 'discussion_type': None, 'num_comments': 27, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nn7yg/d_removed_50_of_the_weights_from_a_top/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nn7yg/d_removed_50_of_the_weights_from_a_top/', 'subreddit_subscribers': 2842618, 'created_utc': 1703165853.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Was curious about this coding question that I got in last year’s Meta AI Residency coding round (and got rejected after). The question was something on the lines of- code a convolutional neural network from scratch, using numpy and matrices. \\n\\nI was super startled and confused as most of my peers got LC Med questions, and I expected something like that as well (esp cause I didn’t ever mention CNNs in my resume either).\\n\\nBut anyway, was curious if someone had a similar experience/would know the answer?\\n\\nThanks!', 'author_fullname': 't2_d78s0gv9', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Meta AI Residency Interview Question [D]', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18nio9k', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 12, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 12, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703149108.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was curious about this coding question that I got in last year’s Meta AI Residency coding round (and got rejected after). The question was something on the lines of- code a convolutional neural network from scratch, using numpy and matrices. &lt;/p&gt;\\n\\n&lt;p&gt;I was super startled and confused as most of my peers got LC Med questions, and I expected something like that as well (esp cause I didn’t ever mention CNNs in my resume either).&lt;/p&gt;\\n\\n&lt;p&gt;But anyway, was curious if someone had a similar experience/would know the answer?&lt;/p&gt;\\n\\n&lt;p&gt;Thanks!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nio9k', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Immediate-Tailor-275', 'discussion_type': None, 'num_comments': 19, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nio9k/meta_ai_residency_interview_question_d/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nio9k/meta_ai_residency_interview_question_d/', 'subreddit_subscribers': 2842618, 'created_utc': 1703149108.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'What is the opinion on X2Vec Papers.Are the papers well received in the community.How impactful will be a Atom2Vec or Bond2Vec paper ?', 'author_fullname': 't2_pqi16q1jf', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Opinion on X2Vec Papers[D]', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18nnbkq', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703166163.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the opinion on X2Vec Papers.Are the papers well received in the community.How impactful will be a Atom2Vec or Bond2Vec paper ?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nnbkq', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'One_Definition_8975', 'discussion_type': None, 'num_comments': 9, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nnbkq/opinion_on_x2vec_papersd/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nnbkq/opinion_on_x2vec_papersd/', 'subreddit_subscribers': 2842618, 'created_utc': 1703166163.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \" Came across this intriguing [article](https://gizmodo.com/mistral-artificial-intelligence-gpt-3-openai-1851091217) about Mistral, an open-source LLM that recently scored 400 million in funding, now valued at 2 billion. Are open-source LLMs gonna be the future? Considering the trust issues with ChatGPT and the debates about its safety, the idea of open-source LLMs seems to be the best bet imo.\\n\\nUnlike closed-source models, users can verify the privacy claims of open-source models. There have been some good things being said about Mistral, and I only hope such open source LLMs secure enough funding to compete with giants like OpenAI. Maybe then, ChatGPT will also be forced to go open source?\\n\\nWith that said, I'm also hopeful that competitors like [Silatus](https://silatus.com/) and [Durable](https://durable.co/), which already use multiple models, consider using open-source models like Mistral into their frameworks. If that happens, maybe there might be a shift in AI privacy. What do you guys think? Are open-source LLMs the future, especially with the funding backing them?\", 'author_fullname': 't2_tuk02hyv', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] Mistral received funding and is worth billions now. Are open source LLMs the future?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18mv8le', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.96, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 393, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 393, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703080793.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Came across this intriguing &lt;a href=\"https://gizmodo.com/mistral-artificial-intelligence-gpt-3-openai-1851091217\"&gt;article&lt;/a&gt; about Mistral, an open-source LLM that recently scored 400 million in funding, now valued at 2 billion. Are open-source LLMs gonna be the future? Considering the trust issues with ChatGPT and the debates about its safety, the idea of open-source LLMs seems to be the best bet imo.&lt;/p&gt;\\n\\n&lt;p&gt;Unlike closed-source models, users can verify the privacy claims of open-source models. There have been some good things being said about Mistral, and I only hope such open source LLMs secure enough funding to compete with giants like OpenAI. Maybe then, ChatGPT will also be forced to go open source?&lt;/p&gt;\\n\\n&lt;p&gt;With that said, I&amp;#39;m also hopeful that competitors like &lt;a href=\"https://silatus.com/\"&gt;Silatus&lt;/a&gt; and &lt;a href=\"https://durable.co/\"&gt;Durable&lt;/a&gt;, which already use multiple models, consider using open-source models like Mistral into their frameworks. If that happens, maybe there might be a shift in AI privacy. What do you guys think? Are open-source LLMs the future, especially with the funding backing them?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/hOiirUfdGIo4-sKZePRcbulgy6aSid7nsATjMCfzqhg.jpg?auto=webp&amp;s=6ac932e9185d36aedb633a1d46b302f1fa3e7144', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/hOiirUfdGIo4-sKZePRcbulgy6aSid7nsATjMCfzqhg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=363b9b822ccea7edbc3009e009657e9bdc647531', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/hOiirUfdGIo4-sKZePRcbulgy6aSid7nsATjMCfzqhg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3667fede508ceb662ff95e1d7a690cd8829e1f45', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/hOiirUfdGIo4-sKZePRcbulgy6aSid7nsATjMCfzqhg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=42d65821c98766d9ef7250a83016e3b7aca0934d', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/hOiirUfdGIo4-sKZePRcbulgy6aSid7nsATjMCfzqhg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=14e72502df67e74cf48e46083324eeef47f5bf57', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/hOiirUfdGIo4-sKZePRcbulgy6aSid7nsATjMCfzqhg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=de057f33fb778294fa2aa748826511b2f7719013', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/hOiirUfdGIo4-sKZePRcbulgy6aSid7nsATjMCfzqhg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=56679f2d4e119a2aa67c5cdfcc8363a4c10f34ba', 'width': 1080, 'height': 607}], 'variants': {}, 'id': '5kinxY6xVzW3EBMIWsWQltOAa7kLzfpce1O_KwItjQ8'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18mv8le', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'BelowaverageReggie34', 'discussion_type': None, 'num_comments': 141, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18mv8le/d_mistral_received_funding_and_is_worth_billions/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18mv8le/d_mistral_received_funding_and_is_worth_billions/', 'subreddit_subscribers': 2842618, 'created_utc': 1703080793.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Hello folks,\\n\\nsuppose you need to setup an LLM for some trivial task, but in different language. For instance, I have a fair classification LLM but I want the classes being generated in a non-english language. Or another case, you have a good specific-domain chat bot, but the inputs and replies must be in another language.\\n\\nWhat would be the most rational approach:\\n\\n1. replicate LLM directly in the target language\\n\\nor\\n\\n2) do the job with a well-stablished English LLM and than translate the results into your target language?\\n\\nHow to leverage the power of specific-domains models in different languages without having to redo all the job? Is there something like a transfer learning in a different language? How such problem is being addressed in the industry?\\n\\nThanks in advanced', 'author_fullname': 't2_k9joijaxt', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What is the optimal approach when training LLMs? [Discussion]', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18nodpq', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703169208.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks,&lt;/p&gt;\\n\\n&lt;p&gt;suppose you need to setup an LLM for some trivial task, but in different language. For instance, I have a fair classification LLM but I want the classes being generated in a non-english language. Or another case, you have a good specific-domain chat bot, but the inputs and replies must be in another language.&lt;/p&gt;\\n\\n&lt;p&gt;What would be the most rational approach:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;replicate LLM directly in the target language&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;or&lt;/p&gt;\\n\\n&lt;p&gt;2) do the job with a well-stablished English LLM and than translate the results into your target language?&lt;/p&gt;\\n\\n&lt;p&gt;How to leverage the power of specific-domains models in different languages without having to redo all the job? Is there something like a transfer learning in a different language? How such problem is being addressed in the industry?&lt;/p&gt;\\n\\n&lt;p&gt;Thanks in advanced&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nodpq', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Ok-Leather-7733', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nodpq/what_is_the_optimal_approach_when_training_llms/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nodpq/what_is_the_optimal_approach_when_training_llms/', 'subreddit_subscribers': 2842618, 'created_utc': 1703169208.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"Hey everyone,\\n\\nI'm working on a project where I need to integrate the CogVLM model into a Python script. I've looked into the [CogVLM GitHub page](https://github.com/THUDM/CogVLM), but I'm a bit unclear about the best way to get started with it in a Python environment.\\n\\nHas anyone here worked with CogVLM before? I'd be very grateful if you could share some insights or resources on:\\n\\n* Setting up CogVLM for use in a Python script.\\n* Making API calls to CogVLM from Python.\\n* Any sample code or documentation that could help.\\n\\nThanks in advance for your help!  \\n\\n\\nhttps://preview.redd.it/y07c4gb5no7c1.jpg?width=5874&amp;format=pjpg&amp;auto=webp&amp;s=dafbf42eeaf87f94fd5ff9bd90136464550c9c06\", 'author_fullname': 't2_ad7n7gnyp', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] How to Use CogVLM in a Python Script?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': 140, 'top_awarded_type': None, 'hide_score': True, 'media_metadata': {'y07c4gb5no7c1': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 134, 'x': 108, 'u': 'https://preview.redd.it/y07c4gb5no7c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de724a009c95e58b63652e86891dfb2bcfa3c1d2'}, {'y': 269, 'x': 216, 'u': 'https://preview.redd.it/y07c4gb5no7c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b4301e01cf717a60f1cf7d70dd960ae4cac1b06'}, {'y': 398, 'x': 320, 'u': 'https://preview.redd.it/y07c4gb5no7c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4176af38cf9784ec3b332b9420eac32b5ff10239'}, {'y': 797, 'x': 640, 'u': 'https://preview.redd.it/y07c4gb5no7c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c1258da9582c79a814e02fa12da71b7a1854ca22'}, {'y': 1196, 'x': 960, 'u': 'https://preview.redd.it/y07c4gb5no7c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f3ba01264027a3ef31c3d187ee4199b541fb5d9f'}, {'y': 1345, 'x': 1080, 'u': 'https://preview.redd.it/y07c4gb5no7c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a54eba7d9fef9d2289ae5411b7d94cfb86e58c79'}], 's': {'y': 7320, 'x': 5874, 'u': 'https://preview.redd.it/y07c4gb5no7c1.jpg?width=5874&amp;format=pjpg&amp;auto=webp&amp;s=dafbf42eeaf87f94fd5ff9bd90136464550c9c06'}, 'id': 'y07c4gb5no7c1'}}, 'name': 't3_18ns81z', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/J3q7ftKIt1snbeE3AW-wUN5EHGnZucGb1_0y0K3ZhRk.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703179553.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m working on a project where I need to integrate the CogVLM model into a Python script. I&amp;#39;ve looked into the &lt;a href=\"https://github.com/THUDM/CogVLM\"&gt;CogVLM GitHub page&lt;/a&gt;, but I&amp;#39;m a bit unclear about the best way to get started with it in a Python environment.&lt;/p&gt;\\n\\n&lt;p&gt;Has anyone here worked with CogVLM before? I&amp;#39;d be very grateful if you could share some insights or resources on:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Setting up CogVLM for use in a Python script.&lt;/li&gt;\\n&lt;li&gt;Making API calls to CogVLM from Python.&lt;/li&gt;\\n&lt;li&gt;Any sample code or documentation that could help.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Thanks in advance for your help!  &lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/y07c4gb5no7c1.jpg?width=5874&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=dafbf42eeaf87f94fd5ff9bd90136464550c9c06\"&gt;https://preview.redd.it/y07c4gb5no7c1.jpg?width=5874&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=dafbf42eeaf87f94fd5ff9bd90136464550c9c06&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/EJPaz1a0649zefQHDxypvTajp3QSdx9hyd-A73RPuIs.jpg?auto=webp&amp;s=689c930f1fac6f31e25a4afca67e5b74d852bcf5', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/EJPaz1a0649zefQHDxypvTajp3QSdx9hyd-A73RPuIs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4358d8fddb93a7432466e3f843592a92282ca54', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/EJPaz1a0649zefQHDxypvTajp3QSdx9hyd-A73RPuIs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=de37e283938dd68c54156e308b8d91d79752a7f6', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/EJPaz1a0649zefQHDxypvTajp3QSdx9hyd-A73RPuIs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=be4ffdf0a8cf6cdbeee958025c248c83364a74d3', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/EJPaz1a0649zefQHDxypvTajp3QSdx9hyd-A73RPuIs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=86eda098df249a6b5e73d05d6f8b609d87d16e87', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/EJPaz1a0649zefQHDxypvTajp3QSdx9hyd-A73RPuIs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a2a6a4979cccb9c5770bac525e6c901f423fe23c', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/EJPaz1a0649zefQHDxypvTajp3QSdx9hyd-A73RPuIs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cf60502bf057be7abb25f77f746b9bffc08f713e', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'mgX0B1gCJtI4SO9DzncMJg2WwLhG388snM12rVGLNx4'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18ns81z', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Kakachia777', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18ns81z/d_how_to_use_cogvlm_in_a_python_script/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18ns81z/d_how_to_use_cogvlm_in_a_python_script/', 'subreddit_subscribers': 2842618, 'created_utc': 1703179553.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Hey all, I wanted to get some hands on practice with Mamba to see how well the smaller models work in practice. I thought question answering would be a nice task to see how much inherent knowledge the model had.\\n\\nTLDR \\\\~ I trained the 130m Mamba model on SQuAD with a template as follows\\n\\n\\\\`\\\\`\\\\`\\n\\n{context}\\n\\n&amp;#x200B;\\n\\nQ: {question}\\n\\nA: {answer}\\n\\n\\\\`\\\\`\\\\`\\n\\nI also wanted the model to be able to answer \"I don\\'t know\" if the answer was not contained in the context. So for half of the training data I paired a random question with random context and had the answer be \"I don\\'t know\" to try to help with hallucinations. This seemed to work reasonably well anecdotally kicking the tires, but only had a 12% accuracy on the SQuAD held out set in practice. \\n\\nFull experiment details, everything I tried, and the code are linked.\\n\\n[https://blog.oxen.ai/practical-ml-dive-how-to-train-mamba-for-question-answering/](https://blog.oxen.ai/practical-ml-dive-how-to-train-mamba-for-question-answering/)\\n\\nI had a hard time training anything over 790m on a Lambda Labs machine with 24GB VRAM, and also had a little success prompt engineering the 2.8b models. I am currently training the 790m model and will release it when it\\'s done.\\n\\nHas anyone else has success training Mamba on any real world tasks? \\n\\nMaybe the larger models would be more promising, I just didn\\'t have enough compute, and think it would be much more economical to be able to run a smaller model in production.\\n\\n&amp;#x200B;', 'author_fullname': 't2_90isk4fs', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[R] Experiments fine-tuning Mamba 130m on the SQuAD Question Answering dataset', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18nd76d', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.97, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 25, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 25, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703129277.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I wanted to get some hands on practice with Mamba to see how well the smaller models work in practice. I thought question answering would be a nice task to see how much inherent knowledge the model had.&lt;/p&gt;\\n\\n&lt;p&gt;TLDR ~ I trained the 130m Mamba model on SQuAD with a template as follows&lt;/p&gt;\\n\\n&lt;p&gt;```&lt;/p&gt;\\n\\n&lt;p&gt;{context}&lt;/p&gt;\\n\\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\\n\\n&lt;p&gt;Q: {question}&lt;/p&gt;\\n\\n&lt;p&gt;A: {answer}&lt;/p&gt;\\n\\n&lt;p&gt;```&lt;/p&gt;\\n\\n&lt;p&gt;I also wanted the model to be able to answer &amp;quot;I don&amp;#39;t know&amp;quot; if the answer was not contained in the context. So for half of the training data I paired a random question with random context and had the answer be &amp;quot;I don&amp;#39;t know&amp;quot; to try to help with hallucinations. This seemed to work reasonably well anecdotally kicking the tires, but only had a 12% accuracy on the SQuAD held out set in practice. &lt;/p&gt;\\n\\n&lt;p&gt;Full experiment details, everything I tried, and the code are linked.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\"https://blog.oxen.ai/practical-ml-dive-how-to-train-mamba-for-question-answering/\"&gt;https://blog.oxen.ai/practical-ml-dive-how-to-train-mamba-for-question-answering/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I had a hard time training anything over 790m on a Lambda Labs machine with 24GB VRAM, and also had a little success prompt engineering the 2.8b models. I am currently training the 790m model and will release it when it&amp;#39;s done.&lt;/p&gt;\\n\\n&lt;p&gt;Has anyone else has success training Mamba on any real world tasks? &lt;/p&gt;\\n\\n&lt;p&gt;Maybe the larger models would be more promising, I just didn&amp;#39;t have enough compute, and think it would be much more economical to be able to run a smaller model in production.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/mBA7uLHDt5pZgsDvR4ckLd7b8YhdaQAM84OPr4p__8w.jpg?auto=webp&amp;s=08586b2dbdaeed1c3cc5abd6ccdd28a5155207bd', 'width': 1024, 'height': 1024}, 'resolutions': [{'url': 'https://external-preview.redd.it/mBA7uLHDt5pZgsDvR4ckLd7b8YhdaQAM84OPr4p__8w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fce959e903aa8d7ab19d56d970aa8dcf6be8c479', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/mBA7uLHDt5pZgsDvR4ckLd7b8YhdaQAM84OPr4p__8w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1a07ede004a800c8d1e96bbc386890d3e84268fa', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/mBA7uLHDt5pZgsDvR4ckLd7b8YhdaQAM84OPr4p__8w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=859e91ad65930a325f80a8542358b8fe5ebd2a38', 'width': 320, 'height': 320}, {'url': 'https://external-preview.redd.it/mBA7uLHDt5pZgsDvR4ckLd7b8YhdaQAM84OPr4p__8w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a5419ded8433f4ec444ed53c06e84077034b0b0c', 'width': 640, 'height': 640}, {'url': 'https://external-preview.redd.it/mBA7uLHDt5pZgsDvR4ckLd7b8YhdaQAM84OPr4p__8w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f1e3635f4505c2d36cfdbedf9da400a24a18b2d5', 'width': 960, 'height': 960}], 'variants': {}, 'id': 'YIIxMi5N00yvruWngeBaqH3WNY719f7XTEsfv9Y-rfo'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nd76d', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'FallMindless3563', 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nd76d/r_experiments_finetuning_mamba_130m_on_the_squad/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nd76d/r_experiments_finetuning_mamba_130m_on_the_squad/', 'subreddit_subscribers': 2842618, 'created_utc': 1703129277.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"I'm excited to introduce Emu2, the latest generative multimodal model developed by the Beijing Academy of Artificial Intelligence (BAAI). Emu2 is an open-source initiative that reflects BAAI's commitment to fostering open, secure, and responsible AI research. It's designed to enhance AI's proficiency in handling tasks across various modalities with minimal examples and straightforward instructions.\\n\\nEmu2 has demonstrated superior performance over other large-scale models like Flamingo-80B in few-shot multimodal understanding tasks. It serves as a versatile base model for developers, providing a flexible platform for crafting specialized multimodal applications.\\n\\nKey features of Emu2 include:\\n\\n\\\\- A more streamlined modeling framework than its predecessor, Emu.\\n\\n\\\\- A decoder capable of reconstructing images from the encoder's semantic space.\\n\\n\\\\- An expansion to 37 billion parameters, boosting both capabilities and generalization.\\n\\nBAAI has also released fine-tuned versions, Emu2-Chat for visual understanding and Emu2-Gen for visual generation, which stand as some of the most powerful open-source models available today.\\n\\nHere are the resources for those interested in exploring or contributing to Emu2:\\n\\n\\\\- Project: https://baaivision.github.io/emu2/\\n\\n\\\\- Model: https://huggingface.co/BAAI/Emu2\\n\\n\\\\- Code: https://github.com/baaivision/Emu/Emu2\\n\\n\\\\- Demo: https://huggingface.co/spaces/BAAI/Emu2\\n\\n\\\\- Paper: https://arxiv.org/abs/2312.13286\\n\\nWe welcome your feedback to help us improve. Let's collaborate to push the boundaries of multimodal AI!\", 'author_fullname': 't2_3v7ero45', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[P] Emu2: A Gemini-like open-source 37B Multimodal Model', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18ngb9b', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.86, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 10, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 10, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703139693.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m excited to introduce Emu2, the latest generative multimodal model developed by the Beijing Academy of Artificial Intelligence (BAAI). Emu2 is an open-source initiative that reflects BAAI&amp;#39;s commitment to fostering open, secure, and responsible AI research. It&amp;#39;s designed to enhance AI&amp;#39;s proficiency in handling tasks across various modalities with minimal examples and straightforward instructions.&lt;/p&gt;\\n\\n&lt;p&gt;Emu2 has demonstrated superior performance over other large-scale models like Flamingo-80B in few-shot multimodal understanding tasks. It serves as a versatile base model for developers, providing a flexible platform for crafting specialized multimodal applications.&lt;/p&gt;\\n\\n&lt;p&gt;Key features of Emu2 include:&lt;/p&gt;\\n\\n&lt;p&gt;- A more streamlined modeling framework than its predecessor, Emu.&lt;/p&gt;\\n\\n&lt;p&gt;- A decoder capable of reconstructing images from the encoder&amp;#39;s semantic space.&lt;/p&gt;\\n\\n&lt;p&gt;- An expansion to 37 billion parameters, boosting both capabilities and generalization.&lt;/p&gt;\\n\\n&lt;p&gt;BAAI has also released fine-tuned versions, Emu2-Chat for visual understanding and Emu2-Gen for visual generation, which stand as some of the most powerful open-source models available today.&lt;/p&gt;\\n\\n&lt;p&gt;Here are the resources for those interested in exploring or contributing to Emu2:&lt;/p&gt;\\n\\n&lt;p&gt;- Project: &lt;a href=\"https://baaivision.github.io/emu2/\"&gt;https://baaivision.github.io/emu2/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;- Model: &lt;a href=\"https://huggingface.co/BAAI/Emu2\"&gt;https://huggingface.co/BAAI/Emu2&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;- Code: &lt;a href=\"https://github.com/baaivision/Emu/Emu2\"&gt;https://github.com/baaivision/Emu/Emu2&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;- Demo: &lt;a href=\"https://huggingface.co/spaces/BAAI/Emu2\"&gt;https://huggingface.co/spaces/BAAI/Emu2&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;- Paper: &lt;a href=\"https://arxiv.org/abs/2312.13286\"&gt;https://arxiv.org/abs/2312.13286&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;We welcome your feedback to help us improve. Let&amp;#39;s collaborate to push the boundaries of multimodal AI!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18ngb9b', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'lukai-baai', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18ngb9b/p_emu2_a_geminilike_opensource_37b_multimodal/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18ngb9b/p_emu2_a_geminilike_opensource_37b_multimodal/', 'subreddit_subscribers': 2842618, 'created_utc': 1703139693.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '**Paper**: [https://arxiv.org/abs/2312.03863](https://arxiv.org/abs/2312.03863)\\n\\n**Literature repository**: [https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey](https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey)\\n\\n**Abstract**:\\n\\n&gt;Large Language Models (LLMs) have demonstrated remarkable capabilities  in important tasks such as natural language understanding, language  generation, and complex reasoning and have the potential to make a  substantial impact on our society. Such capabilities, however, come with  the considerable resources they demand, highlighting the strong need to  develop effective techniques for addressing their efficiency  challenges. In this survey, we provide a systematic and comprehensive  review of efficient LLMs research. We organize the literature in a  taxonomy consisting of three main categories, covering distinct yet  interconnected efficient LLMs topics from model-centric, data-centric,  and framework-centric perspective, respectively. We have also created a  GitHub repository where we compile the papers featured in this survey at  [this https URL](https://github.com/AIoT-MLSys-Lab/EfficientLLMs), [this https URL](https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey),  and will actively maintain this repository and incorporate new research  as it emerges. We hope our survey can serve as a valuable resource to  help researchers and practitioners gain a systematic understanding of  the research developments in efficient LLMs and inspire them to  contribute to this important and exciting field.', 'author_fullname': 't2_mveclxvsc', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[R] Efficient Large Language Models: A Survey', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18nhvcd', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.88, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703145712.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Paper&lt;/strong&gt;: &lt;a href=\"https://arxiv.org/abs/2312.03863\"&gt;https://arxiv.org/abs/2312.03863&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Literature repository&lt;/strong&gt;: &lt;a href=\"https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey\"&gt;https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;Large Language Models (LLMs) have demonstrated remarkable capabilities  in important tasks such as natural language understanding, language  generation, and complex reasoning and have the potential to make a  substantial impact on our society. Such capabilities, however, come with  the considerable resources they demand, highlighting the strong need to  develop effective techniques for addressing their efficiency  challenges. In this survey, we provide a systematic and comprehensive  review of efficient LLMs research. We organize the literature in a  taxonomy consisting of three main categories, covering distinct yet  interconnected efficient LLMs topics from model-centric, data-centric,  and framework-centric perspective, respectively. We have also created a  GitHub repository where we compile the papers featured in this survey at  &lt;a href=\"https://github.com/AIoT-MLSys-Lab/EfficientLLMs\"&gt;this https URL&lt;/a&gt;, &lt;a href=\"https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey\"&gt;this https URL&lt;/a&gt;,  and will actively maintain this repository and incorporate new research  as it emerges. We hope our survey can serve as a valuable resource to  help researchers and practitioners gain a systematic understanding of  the research developments in efficient LLMs and inspire them to  contribute to this important and exciting field.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nhvcd', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'APaperADay', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nhvcd/r_efficient_large_language_models_a_survey/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nhvcd/r_efficient_large_language_models_a_survey/', 'subreddit_subscribers': 2842618, 'created_utc': 1703145712.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"Currently, most generative processes take place on cloud, as they often require enormous memory and processing power. Smaller, \\\\~8B models can already be ran on most average consumer hardware but offer lower quality results, still with a severely reduced generation speed. Moreover, privacy remains a concern when using services.\\n\\nApple recently released a [paper](https://arxiv.org/pdf/2312.11514.pdf) describing a method to run heavy LLMs on devices with limited memory, and the company is still expected to announce their product, following Google's Gemini.\\n\\nNow, apple has a history of favoring on-device execution and overcoming physical limits, so it is possible to expect that they might set the trend of locally-hosted models and heavy optimization, allowing streamlined generative experience without the need of remote calls.\\n\\nCombined with steadily growing open-source community, this seems promising to me. I'd like to hear some opinions on this topic, but to me it seems like the current rate of advancement means it is possible that by the end of 2024 it will be possible to reliably run medium-size LLMs on consumer hardware.\", 'author_fullname': 't2_3a3s88pd', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] Are medium-sized LLMs running on-device on consumer hardware a realistic expectation in 2024?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18n3fre', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.93, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 58, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 58, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703101730.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, most generative processes take place on cloud, as they often require enormous memory and processing power. Smaller, ~8B models can already be ran on most average consumer hardware but offer lower quality results, still with a severely reduced generation speed. Moreover, privacy remains a concern when using services.&lt;/p&gt;\\n\\n&lt;p&gt;Apple recently released a &lt;a href=\"https://arxiv.org/pdf/2312.11514.pdf\"&gt;paper&lt;/a&gt; describing a method to run heavy LLMs on devices with limited memory, and the company is still expected to announce their product, following Google&amp;#39;s Gemini.&lt;/p&gt;\\n\\n&lt;p&gt;Now, apple has a history of favoring on-device execution and overcoming physical limits, so it is possible to expect that they might set the trend of locally-hosted models and heavy optimization, allowing streamlined generative experience without the need of remote calls.&lt;/p&gt;\\n\\n&lt;p&gt;Combined with steadily growing open-source community, this seems promising to me. I&amp;#39;d like to hear some opinions on this topic, but to me it seems like the current rate of advancement means it is possible that by the end of 2024 it will be possible to reliably run medium-size LLMs on consumer hardware.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18n3fre', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'NightestOfTheOwls', 'discussion_type': None, 'num_comments': 43, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18n3fre/d_are_mediumsized_llms_running_ondevice_on/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18n3fre/d_are_mediumsized_llms_running_ondevice_on/', 'subreddit_subscribers': 2842618, 'created_utc': 1703101730.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'My X is composed of an x1 and an x2. I want to feed the prediction model a value for x1 and have it return the x2 which will give the smallest value of y. Does this have a name? Can someone point me in the right direction of what to read or help me out?', 'author_fullname': 't2_pxwrjdixt', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'how do I find my input? [D] [P]', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_18ns1uy', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703179113.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My X is composed of an x1 and an x2. I want to feed the prediction model a value for x1 and have it return the x2 which will give the smallest value of y. Does this have a name? Can someone point me in the right direction of what to read or help me out?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18ns1uy', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'GlassWalkerKinfolk', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18ns1uy/how_do_i_find_my_input_d_p/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18ns1uy/how_do_i_find_my_input_d_p/', 'subreddit_subscribers': 2842618, 'created_utc': 1703179113.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Does anyone know when the datasets will be re-published without any CSAM?', 'author_fullname': 't2_mbc0bpphd', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] LAION datasets', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_18nrnzx', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703178087.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know when the datasets will be re-published without any CSAM?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nrnzx', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'AromaticCantaloupe19', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nrnzx/d_laion_datasets/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nrnzx/d_laion_datasets/', 'subreddit_subscribers': 2842618, 'created_utc': 1703178087.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'The SPLK (*Sparlek*) Coffee Demo assesses your personality traits to determine the ideal coffee for you! This 2-minute questionnaire would assist us wonderfully to get this demonstration up and running! We are shooting for 1,000 responses to contribute to our database and ultimately feed to our custom-made AI model. If you are a coffee enthusiast and you have 2 minutes to spare, please consider contributing some samples of information! \\n\\n  \\n**SURVEY:**  \\n[https://forms.gle/UrDvf776N6B1R3sE7](https://forms.gle/UrDvf776N6B1R3sE7)', 'author_fullname': 't2_7cxdv2n7', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Tailored coffee recommendations, powered by data science and machine learning [P]', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18nok4d', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703169692.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The SPLK (&lt;em&gt;Sparlek&lt;/em&gt;) Coffee Demo assesses your personality traits to determine the ideal coffee for you! This 2-minute questionnaire would assist us wonderfully to get this demonstration up and running! We are shooting for 1,000 responses to contribute to our database and ultimately feed to our custom-made AI model. If you are a coffee enthusiast and you have 2 minutes to spare, please consider contributing some samples of information! &lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;SURVEY:&lt;/strong&gt;&lt;br/&gt;\\n&lt;a href=\"https://forms.gle/UrDvf776N6B1R3sE7\"&gt;https://forms.gle/UrDvf776N6B1R3sE7&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/_DJobxRfA_xNITufNiEDRh7r_-bI0P9llD0aABfIy70.jpg?auto=webp&amp;s=f41e719a5d337719e4f81d547fcc78e5ae941ee3', 'width': 1200, 'height': 630}, 'resolutions': [{'url': 'https://external-preview.redd.it/_DJobxRfA_xNITufNiEDRh7r_-bI0P9llD0aABfIy70.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d75fe3c07d6e54b951b756df9f30695b74874320', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/_DJobxRfA_xNITufNiEDRh7r_-bI0P9llD0aABfIy70.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6fbd4db264ffd481fe28dc973e2e752381d79ba5', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/_DJobxRfA_xNITufNiEDRh7r_-bI0P9llD0aABfIy70.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=761f7bed77aeb715d5829bce8c9d28b151b42998', 'width': 320, 'height': 168}, {'url': 'https://external-preview.redd.it/_DJobxRfA_xNITufNiEDRh7r_-bI0P9llD0aABfIy70.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ae16b0c2aae6f818ad7e995fc58ec48904f9d9e', 'width': 640, 'height': 336}, {'url': 'https://external-preview.redd.it/_DJobxRfA_xNITufNiEDRh7r_-bI0P9llD0aABfIy70.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ecf8bbd2a53c7499b6f61370ffb3837aa1c5a37a', 'width': 960, 'height': 504}, {'url': 'https://external-preview.redd.it/_DJobxRfA_xNITufNiEDRh7r_-bI0P9llD0aABfIy70.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9d8bce7af047746aaa7f2378cffca5cf4425282e', 'width': 1080, 'height': 567}], 'variants': {}, 'id': 'vJ_mgCc0LcbG5FCX7SKq56BsYWMv50zIP9cy2vosZnM'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nok4d', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'SnooMaps9269', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nok4d/tailored_coffee_recommendations_powered_by_data/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nok4d/tailored_coffee_recommendations_powered_by_data/', 'subreddit_subscribers': 2842618, 'created_utc': 1703169692.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': ' I\\'ve recently started my journey into deep learning by taking courses on CNNs and RNNs. I\\'m particularly interested in understanding how the \"Stable Diffusion\" AI model was built and its inner workings.\\n\\nConsidering my current knowledge, could you provide me with a roadmap or suggest resources to deepen my understanding? What topics should I delve into next to bridge the gap and comprehend the intricacies of stable diffusion-based models?\\n\\nAny advice, recommended courses, or learning paths would be greatly appreciated! Thank you in advance for your insights.', 'author_fullname': 't2_qf1gnufc0', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] Learning Path for Understanding the Construction of \"Stable Diffusion\" AI Model', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18noj0j', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.4, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703169614.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently started my journey into deep learning by taking courses on CNNs and RNNs. I&amp;#39;m particularly interested in understanding how the &amp;quot;Stable Diffusion&amp;quot; AI model was built and its inner workings.&lt;/p&gt;\\n\\n&lt;p&gt;Considering my current knowledge, could you provide me with a roadmap or suggest resources to deepen my understanding? What topics should I delve into next to bridge the gap and comprehend the intricacies of stable diffusion-based models?&lt;/p&gt;\\n\\n&lt;p&gt;Any advice, recommended courses, or learning paths would be greatly appreciated! Thank you in advance for your insights.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18noj0j', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Ok_Science_867', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18noj0j/d_learning_path_for_understanding_the/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18noj0j/d_learning_path_for_understanding_the/', 'subreddit_subscribers': 2842618, 'created_utc': 1703169614.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '**Paper**: [https://arxiv.org/abs/2312.00678](https://arxiv.org/abs/2312.00678)\\n\\n**Literature repository**: [https://github.com/tding1/Efficient-LLM-Survey](https://github.com/tding1/Efficient-LLM-Survey)\\n\\n**Abstract**:\\n\\n&gt;The rapid growth of Large Language Models (LLMs) has been a driving  force in transforming various domains, reshaping the artificial general  intelligence landscape. However, the increasing computational and memory  demands of these models present substantial challenges, hindering both  academic research and practical applications. To address these issues, a  wide array of methods, including both algorithmic and hardware  solutions, have been developed to enhance the efficiency of LLMs. This  survey delivers a comprehensive review of algorithmic advancements aimed  at improving LLM efficiency. Unlike other surveys that typically focus  on specific areas such as training or model compression, this paper  examines the multi-faceted dimensions of efficiency essential for the  end-to-end algorithmic development of LLMs. Specifically, it covers  various topics related to efficiency, including scaling laws, data  utilization, architectural innovations, training and tuning strategies,  and inference techniques. This paper aims to serve as a valuable  resource for researchers and practitioners, laying the groundwork for  future innovations in this critical research area. Our repository of  relevant references is maintained at url{[this https URL](https://github.com/tding1/Efficient-LLM-Survey)}.', 'author_fullname': 't2_mveclxvsc', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[R] The Efficiency Spectrum of Large Language Models: An Algorithmic Survey', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18nhz3v', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.8, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703146156.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Paper&lt;/strong&gt;: &lt;a href=\"https://arxiv.org/abs/2312.00678\"&gt;https://arxiv.org/abs/2312.00678&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Literature repository&lt;/strong&gt;: &lt;a href=\"https://github.com/tding1/Efficient-LLM-Survey\"&gt;https://github.com/tding1/Efficient-LLM-Survey&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;:&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n&lt;p&gt;The rapid growth of Large Language Models (LLMs) has been a driving  force in transforming various domains, reshaping the artificial general  intelligence landscape. However, the increasing computational and memory  demands of these models present substantial challenges, hindering both  academic research and practical applications. To address these issues, a  wide array of methods, including both algorithmic and hardware  solutions, have been developed to enhance the efficiency of LLMs. This  survey delivers a comprehensive review of algorithmic advancements aimed  at improving LLM efficiency. Unlike other surveys that typically focus  on specific areas such as training or model compression, this paper  examines the multi-faceted dimensions of efficiency essential for the  end-to-end algorithmic development of LLMs. Specifically, it covers  various topics related to efficiency, including scaling laws, data  utilization, architectural innovations, training and tuning strategies,  and inference techniques. This paper aims to serve as a valuable  resource for researchers and practitioners, laying the groundwork for  future innovations in this critical research area. Our repository of  relevant references is maintained at url{&lt;a href=\"https://github.com/tding1/Efficient-LLM-Survey\"&gt;this https URL&lt;/a&gt;}.&lt;/p&gt;\\n&lt;/blockquote&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nhz3v', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'APaperADay', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nhz3v/r_the_efficiency_spectrum_of_large_language/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nhz3v/r_the_efficiency_spectrum_of_large_language/', 'subreddit_subscribers': 2842618, 'created_utc': 1703146156.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"I'm currently developing a Dash application that incorporates a variety of graphs including line graphs, pie plots, treemaps, tables, spider plots, and Gantt charts. This application allows user-based modifications and responds dynamically to user interactions with the graphs and tables. Also certain modification is three. If a user select a data point on the graph, user see the detailed information about the data point below the graph. Similarly with the table an pi plot. Also A key aspect of our app is its integration with a trained machine learning model to display data. However, we're working with a considerably large dataset, ranging from 1-10 million rows and 400-1000 columns of text data (Json,csv). Given this scale, a critical question arises:\\n\\n&amp;#x200B;\\n\\nCan Dash Plotly efficiently scale to accommodate 100 to 1000 users simultaneously? In our current test phase, we've encountered an issue with the initial loading time of the app, which is approximately 15 seconds on both Google Cloud Platform and AWS. We've implemented some optimizations, such as using lru\\\\_cache, flask\\\\_compress , and setting prevent\\\\_initial\\\\_call=True in callbacks. These tweaks have offered some improvements, but not significantly. Our trial with Gunicorn (configured with 8 workers and 4 threads) interestingly resulted in slower performance, contrary to expectations. We haven't yet explored asynchronous routes, and I'm curious if this could be a potential solution. This brings me to another consideration: the necessity of Dash Enterprise. Based on my research from sources like Data Revenue and Dash Plotly's own documentation, Dash Enterprise offers additional features like job queues, which are not included in the standard version.\\n\\n&amp;#x200B;\\n\\nWould Dash Enterprise be a more suitable solution for our requirements? I am keen to hear from anyone who has experience scaling Dashboard applications, especially those dealing with large datasets and heavy user interaction. Any insights or suggestions would be greatly appreciated.\\n\\n&amp;#x200B;\\n\\nGiven the context, we are also evaluating; elixir phoenix, bunjs\\n\\n&amp;#x200B;\\n\\nAppreciate it.\", 'author_fullname': 't2_m0r3pnug', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[P] Scaling Challenges with Dashboard Plotly vs Tableau vs bunjs for High-Volume Data and User Interaction', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18nnpj4', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703167291.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently developing a Dash application that incorporates a variety of graphs including line graphs, pie plots, treemaps, tables, spider plots, and Gantt charts. This application allows user-based modifications and responds dynamically to user interactions with the graphs and tables. Also certain modification is three. If a user select a data point on the graph, user see the detailed information about the data point below the graph. Similarly with the table an pi plot. Also A key aspect of our app is its integration with a trained machine learning model to display data. However, we&amp;#39;re working with a considerably large dataset, ranging from 1-10 million rows and 400-1000 columns of text data (Json,csv). Given this scale, a critical question arises:&lt;/p&gt;\\n\\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\\n\\n&lt;p&gt;Can Dash Plotly efficiently scale to accommodate 100 to 1000 users simultaneously? In our current test phase, we&amp;#39;ve encountered an issue with the initial loading time of the app, which is approximately 15 seconds on both Google Cloud Platform and AWS. We&amp;#39;ve implemented some optimizations, such as using lru_cache, flask_compress , and setting prevent_initial_call=True in callbacks. These tweaks have offered some improvements, but not significantly. Our trial with Gunicorn (configured with 8 workers and 4 threads) interestingly resulted in slower performance, contrary to expectations. We haven&amp;#39;t yet explored asynchronous routes, and I&amp;#39;m curious if this could be a potential solution. This brings me to another consideration: the necessity of Dash Enterprise. Based on my research from sources like Data Revenue and Dash Plotly&amp;#39;s own documentation, Dash Enterprise offers additional features like job queues, which are not included in the standard version.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\\n\\n&lt;p&gt;Would Dash Enterprise be a more suitable solution for our requirements? I am keen to hear from anyone who has experience scaling Dashboard applications, especially those dealing with large datasets and heavy user interaction. Any insights or suggestions would be greatly appreciated.&lt;/p&gt;\\n\\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\\n\\n&lt;p&gt;Given the context, we are also evaluating; elixir phoenix, bunjs&lt;/p&gt;\\n\\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\\n\\n&lt;p&gt;Appreciate it.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nnpj4', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Alertt_53', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nnpj4/p_scaling_challenges_with_dashboard_plotly_vs/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nnpj4/p_scaling_challenges_with_dashboard_plotly_vs/', 'subreddit_subscribers': 2842618, 'created_utc': 1703167291.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Are SELFIES right now the sota?Any helpful resources?', 'author_fullname': 't2_pqi16q1jf', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Does anyone here work with SELFIES in deep learning in Chemistry [D]?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18nmn5r', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.6, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703164090.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are SELFIES right now the sota?Any helpful resources?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nmn5r', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'One_Definition_8975', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nmn5r/does_anyone_here_work_with_selfies_in_deep/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nmn5r/does_anyone_here_work_with_selfies_in_deep/', 'subreddit_subscribers': 2842618, 'created_utc': 1703164090.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'I recently got interested in Le Cam equation which informally is useful to find the relevant metric in the hypothesis class/ collection of densities in order to find (sub)linear rate of convergence for the minimax estimation of error.   \\nI will leave some references and I’m interested to know more about a geometrical interpretation to understand the intuition behind it. I’m interested in work where this approach was used, particularly in bandits, I would also be grateful if you can recommend books/lectures to understand it.  \\n\\\\[1\\\\] \\\\[Shamindra et Al. Revisiting Le Cam’s Equation: Exact Minimax Rates over Convex Density Classes\\\\](https://arxiv.org/pdf/2210.11436.pdf)  \\n\\\\[2\\\\] \\\\[Bilodeau et Al Minimax Rates for Conditional Density Estimation via Empirical Entropy\\\\](https://arxiv.org/abs/2109.10461)  \\n\\\\[3\\\\] \\\\[Alxander Rakhlin et Al. Empirical entropy, minimax regret and minimax risk\\\\](https://arxiv.org/pdf/1308.1147.pdf)', 'author_fullname': 't2_7txolunh', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Why Le Cam equation is not popular but very useful ? [R]', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18n9rin', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.78, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 10, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 10, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703118633.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently got interested in Le Cam equation which informally is useful to find the relevant metric in the hypothesis class/ collection of densities in order to find (sub)linear rate of convergence for the minimax estimation of error.&lt;br/&gt;\\nI will leave some references and I’m interested to know more about a geometrical interpretation to understand the intuition behind it. I’m interested in work where this approach was used, particularly in bandits, I would also be grateful if you can recommend books/lectures to understand it.&lt;br/&gt;\\n[1] [Shamindra et Al. Revisiting Le Cam’s Equation: Exact Minimax Rates over Convex Density Classes](&lt;a href=\"https://arxiv.org/pdf/2210.11436.pdf\"&gt;https://arxiv.org/pdf/2210.11436.pdf&lt;/a&gt;)&lt;br/&gt;\\n[2] [Bilodeau et Al Minimax Rates for Conditional Density Estimation via Empirical Entropy](&lt;a href=\"https://arxiv.org/abs/2109.10461\"&gt;https://arxiv.org/abs/2109.10461&lt;/a&gt;)&lt;br/&gt;\\n[3] [Alxander Rakhlin et Al. Empirical entropy, minimax regret and minimax risk](&lt;a href=\"https://arxiv.org/pdf/1308.1147.pdf\"&gt;https://arxiv.org/pdf/1308.1147.pdf&lt;/a&gt;)&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18n9rin', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Any-Ad-3888', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18n9rin/why_le_cam_equation_is_not_popular_but_very/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18n9rin/why_le_cam_equation_is_not_popular_but_very/', 'subreddit_subscribers': 2842618, 'created_utc': 1703118633.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'So I’m currently using colab pro+ which I have been happy with for the notebooks and the powerful GPUs. I only have a m1 MacBook Air and for the most part do off and on side projects. I’ve been looking for a more “complete” cloud environment where I can have access to a true IDE (like vs code) to write python code or work in a notebook, have full   Git control, and GPU backed.\\n\\nWhen looking around at colabs, paperspace, vast etc they all still seem to be notebook based. My questions is GCP w/ a gpu and a VM a good option or other options out there? Co lab pro+ is $50/month and if I only average a couple days a month on demand pricing of cloud may be reasonable.', 'author_fullname': 't2_4sh5l7zu', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] PyTorch Cloud IDE - need clarification', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18nlwuc', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703161693.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I’m currently using colab pro+ which I have been happy with for the notebooks and the powerful GPUs. I only have a m1 MacBook Air and for the most part do off and on side projects. I’ve been looking for a more “complete” cloud environment where I can have access to a true IDE (like vs code) to write python code or work in a notebook, have full   Git control, and GPU backed.&lt;/p&gt;\\n\\n&lt;p&gt;When looking around at colabs, paperspace, vast etc they all still seem to be notebook based. My questions is GCP w/ a gpu and a VM a good option or other options out there? Co lab pro+ is $50/month and if I only average a couple days a month on demand pricing of cloud may be reasonable.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nlwuc', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'SuperbMonk4403', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nlwuc/d_pytorch_cloud_ide_need_clarification/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nlwuc/d_pytorch_cloud_ide_need_clarification/', 'subreddit_subscribers': 2842618, 'created_utc': 1703161693.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"Hi everyone,\\n\\nI'm curious about the latest advancements in natural language processing (NLP) and machine learning, especially in the context of personality analysis. Specifically, I'm interested in models that can predict the Big Five personality traits (Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism) from text data.\\n\\nAs of my last reading, models like BERT and its variants were showing promise in this area. These transformer-based models, known for their deep learning capabilities, seemed to be at the forefront of such applications.\\n\\nHowever, I'm aware that the field of AI and NLP is rapidly evolving, and new techniques and models are constantly emerging. So, I'm reaching out to this community to ask:\\n\\n1. What are the current state-of-the-art models for predicting the Big Five personality traits from text?\\n2. Are there any recent breakthroughs or significant advancements in this specific application of NLP?\\n3. If anyone here has experience in this field, could you share insights or resources where I can learn more about the latest developments?\\n\\nAny academic references, research papers, or personal insights would be greatly appreciated. I'm keen to stay updated with the latest in this fascinating intersection of AI and psychology.\\n\\nThanks in advance!\", 'author_fullname': 't2_6z5d1mtf', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': \"[D] What's the Current State-of-the-Art Model for Predicting Big Five Personality Traits from Text?\", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18no7gk', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.38, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703168719.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m curious about the latest advancements in natural language processing (NLP) and machine learning, especially in the context of personality analysis. Specifically, I&amp;#39;m interested in models that can predict the Big Five personality traits (Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism) from text data.&lt;/p&gt;\\n\\n&lt;p&gt;As of my last reading, models like BERT and its variants were showing promise in this area. These transformer-based models, known for their deep learning capabilities, seemed to be at the forefront of such applications.&lt;/p&gt;\\n\\n&lt;p&gt;However, I&amp;#39;m aware that the field of AI and NLP is rapidly evolving, and new techniques and models are constantly emerging. So, I&amp;#39;m reaching out to this community to ask:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;What are the current state-of-the-art models for predicting the Big Five personality traits from text?&lt;/li&gt;\\n&lt;li&gt;Are there any recent breakthroughs or significant advancements in this specific application of NLP?&lt;/li&gt;\\n&lt;li&gt;If anyone here has experience in this field, could you share insights or resources where I can learn more about the latest developments?&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;Any academic references, research papers, or personal insights would be greatly appreciated. I&amp;#39;m keen to stay updated with the latest in this fascinating intersection of AI and psychology.&lt;/p&gt;\\n\\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18no7gk', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'yachty66', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18no7gk/d_whats_the_current_stateoftheart_model_for/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18no7gk/d_whats_the_current_stateoftheart_model_for/', 'subreddit_subscribers': 2842618, 'created_utc': 1703168719.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"Multiple Label Classification using LLM\\n\\nHi everyone\\n\\nI'm not really well-versed in ML so I want to ask a few question on fine-tuning LLM if that's ok. I'm looking to fine tune some 7B models like llama or mistral 7B.\\n\\nMy use case is in essay evaluations where there are multiple labels (10 out of a total of 100 possible labels) assigned to an essay to produce a score. \\n\\nThese labels I think can be categorized into 4 main type (Vocabulary,.....) which decreases the complexity of each API calls.\\n\\nMy question is, is it possible to fine tune an LLM to perform such a complex task, given I will eventually gather enough data ~10K entries?\\n\\nAnd is this process any different from regular promt-to-response fine tuning llm?\", 'author_fullname': 't2_exnvt94iy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D]Multiple Labels Classification using LLM', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18nk3wa', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703155001.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Multiple Label Classification using LLM&lt;/p&gt;\\n\\n&lt;p&gt;Hi everyone&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m not really well-versed in ML so I want to ask a few question on fine-tuning LLM if that&amp;#39;s ok. I&amp;#39;m looking to fine tune some 7B models like llama or mistral 7B.&lt;/p&gt;\\n\\n&lt;p&gt;My use case is in essay evaluations where there are multiple labels (10 out of a total of 100 possible labels) assigned to an essay to produce a score. &lt;/p&gt;\\n\\n&lt;p&gt;These labels I think can be categorized into 4 main type (Vocabulary,.....) which decreases the complexity of each API calls.&lt;/p&gt;\\n\\n&lt;p&gt;My question is, is it possible to fine tune an LLM to perform such a complex task, given I will eventually gather enough data ~10K entries?&lt;/p&gt;\\n\\n&lt;p&gt;And is this process any different from regular promt-to-response fine tuning llm?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nk3wa', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Quirky_Musician6861', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nk3wa/dmultiple_labels_classification_using_llm/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nk3wa/dmultiple_labels_classification_using_llm/', 'subreddit_subscribers': 2842618, 'created_utc': 1703155001.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': \"I'm trying to get a better intuition and test a few hypotheses about the effect of softmax temperature on Transformer models, and the optimal choice of temperature based on various dataset settings (eg data augmentations, class imbalance). I want my dataset and model to be large enough such that the lessons learned will hopefully generalize somewhat to larger scenarios. On the other hand, I want to be able try a number of settings so I don't want training to take too long. I also only have a system with 2x RTX 3080s. What's a good dataset and model size to run these experiments? Also, presumably to make this realistic I need to pretrain from scratch, right? I'm thinking maybe a ViT model with 4 heads and 128 hidden dimensions for CIFAR-10 -- does this make sense?\", 'author_fullname': 't2_e28a8rf', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[R] How to test hypotheses about optimal softmax temperature for Transformer model', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18nghx0', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703140337.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to get a better intuition and test a few hypotheses about the effect of softmax temperature on Transformer models, and the optimal choice of temperature based on various dataset settings (eg data augmentations, class imbalance). I want my dataset and model to be large enough such that the lessons learned will hopefully generalize somewhat to larger scenarios. On the other hand, I want to be able try a number of settings so I don&amp;#39;t want training to take too long. I also only have a system with 2x RTX 3080s. What&amp;#39;s a good dataset and model size to run these experiments? Also, presumably to make this realistic I need to pretrain from scratch, right? I&amp;#39;m thinking maybe a ViT model with 4 heads and 128 hidden dimensions for CIFAR-10 -- does this make sense?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18nghx0', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'halvin_n_cobbes', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18nghx0/r_how_to_test_hypotheses_about_optimal_softmax/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18nghx0/r_how_to_test_hypotheses_about_optimal_softmax/', 'subreddit_subscribers': 2842618, 'created_utc': 1703140337.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Hello all! Sharing my new YT video about Multimodal LLMs and how they generate images. I go over concepts like VQ-VAE and image tokens, and how these neural networks convert the image generation problem into a language generation problem. Link here for those interested.\\n\\nThanks, hope you enjoy it!\\n\\nhttps://youtu.be/EzDsrEvdgNQ', 'author_fullname': 't2_matylxao', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] How Multimodal LLMs (like Gemini) learn to generate images (A video)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18na690', 'quarantine': False, 'link_flair_text_color': None, 'upvote_ratio': 0.86, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1703119863.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! Sharing my new YT video about Multimodal LLMs and how they generate images. I go over concepts like VQ-VAE and image tokens, and how these neural networks convert the image generation problem into a language generation problem. Link here for those interested.&lt;/p&gt;\\n\\n&lt;p&gt;Thanks, hope you enjoy it!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\"https://youtu.be/EzDsrEvdgNQ\"&gt;https://youtu.be/EzDsrEvdgNQ&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/x0heMkJ9K7d1H0OsMK2ekGOCZwDH_08lphdER6jtKxc.jpg?auto=webp&amp;s=7b32d02f866730f34f19aa9230c515d7ad571a57', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/x0heMkJ9K7d1H0OsMK2ekGOCZwDH_08lphdER6jtKxc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=87cfda65faede92ee168f32a6ab4b0771aed6410', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/x0heMkJ9K7d1H0OsMK2ekGOCZwDH_08lphdER6jtKxc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ff15cebd3750b01d8f0e814d5213cadade99ba57', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/x0heMkJ9K7d1H0OsMK2ekGOCZwDH_08lphdER6jtKxc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cba8e1882afa804bc05e66b320ebd1169207d918', 'width': 320, 'height': 240}], 'variants': {}, 'id': '8VeaoZ8KvyhRGYnYHePKDq3kIbNQpmBjsN4iporiykM'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': None, 'id': '18na690', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'AvvYaa', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/18na690/d_how_multimodal_llms_like_gemini_learn_to/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/18na690/d_how_multimodal_llms_like_gemini_learn_to/', 'subreddit_subscribers': 2842618, 'created_utc': 1703119863.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}], 'before': None}}\n"
     ]
    }
   ],
   "source": [
    "print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your company wants you to get relevant data from that endpoint - ensure that data is easily useable.\n",
    "# Make a CSV file with all relevant data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
